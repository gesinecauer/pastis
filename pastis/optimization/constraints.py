import sys

if sys.version_info[0] < 3:
    raise Exception("Must be using Python 3")

import numpy as np

from absl import logging as absl_logging
absl_logging.set_verbosity('error')
from jax.config import config as jax_config
jax_config.update("jax_platform_name", "cpu")
jax_config.update("jax_enable_x64", True)
import jax.numpy as ag_np
from jax.nn import relu

from .multiscale_optimization import decrease_lengths_res, decrease_counts_res
from .multiscale_optimization import _count_fullres_per_lowres_bead
from .utils_poisson import find_beads_to_remove
from .utils_poisson import _euclidean_distance, _inter_counts
from .counts import ambiguate_counts, _ambiguate_beta
from .likelihoods import poisson_nll, gamma_poisson_nll
from .poisson import relu_min  # TODO temporary (for NDC)


class Constraint(object):
    """Compute loss for the given constraint.

    Prepares cand computes the loss function for the given constraint.

    Parameters
    ----------
    lambda_val : float
        Lambda that specifies how strongly constraint is applied during
        calculation of the entire objective.
    lengths : array_like of int
        Number of beads per homolog of each chromosome.
    ploidy : {1, 2}
        Ploidy, 1 indicates haploid, 2 indicates diploid.
    multiscale_factor : int, optional
        Factor by which to reduce the resolution. A value of 2 halves the
        resolution. A value of 1 indicates full resolution.
    hparams : dict, optional
        Any hyperparameters used for the calculation of constraint.

    Attributes
    ----------
    abbrev : str
        Three-letter abbreviation for constraint name.
    name : str
        Full name of constraint
    during_alpha_infer : bool
        Whether or not this constraint should be computed during inference of
        alpha.
    lambda_val : float
        Lambda that specifies how strongly constraint is applied during
        calculation of the entire objective.
    lengths : array_like of int
        Number of beads per homolog of each chromosome.
    ploidy : {1, 2}
        Ploidy, 1 indicates haploid, 2 indicates diploid.
    multiscale_factor : int, optional
        Factor by which to reduce the resolution. A value of 2 halves the
        resolution. A value of 1 indicates full resolution.
    hparams : dict, optional
        Any hyperparameters used for the calculation of constraint.
    fullres_struct_nan : array of int
        Beads that should be removed (set to NaN) in the full-res structure.
    lowmem : bool, optional
        Whether variables generated by _setup should be saved for subsequent
        iterations.
    """

    def __init__(self, lambda_val, lengths, ploidy, multiscale_factor=1,
                 hparams=None, fullres_struct_nan=None, lowmem=False, mods=[]):
        self.abbrev = None
        self.name = None
        self.during_alpha_infer = None
        self.lambda_val = lambda_val
        self.lengths = lengths
        self.ploidy = ploidy
        self.multiscale_factor = multiscale_factor
        self.hparams = hparams
        self._fullres_struct_nan = fullres_struct_nan  # For self._setup() only
        self._lowmem = lowmem
        self._var = None

    def __str__(self):
        out = [f"CONSTRAINT: {self.name},  LAMBDA={self.lambda_val:g}"]
        if self.hparams is None:
            return "\n".join(out)
        for name, val in self.hparams.items():
            label = f"\t\t\t{name} = "
            if isinstance(val, (np.ndarray, list)):
                out.append(label + np.array2string(
                    val, formatter={'float_kind': lambda x: "%.3g" % x},
                    prefix=" " * len(label), separator=", "))
            elif isinstance(val, float):
                out.append(f"{label}{val:g}")
            else:
                out.append(f"{label}{val}")
        return "\n".join(out)

    def check(self):
        """Check constraints object.

        Check that lambdas are greater than zero, and that necessary
        hyperparameters are supplied."""
        pass

    def _setup(self, counts=None, bias=None):
        """Set up for applying constraint (not specific to inferred params)"""
        pass

    def apply(self, struct, alpha=None, epsilon=None, counts=None, bias=None,
              inferring_alpha=False):

        """Apply constraint using given structure(s).

        Compute loss for the given constraint.

        Parameters
        ----------
        struct : ndarray
            3D chromatin structure(s) for which to compute the constraint.
        alpha : float
            Biophysical parameter of the transfer function used in converting
            counts to wish distances. If alpha is not specified, it will be
            inferred.
        epsilon : float, optional
            TODO
        counts : list of CountsMatrix subclass instances
            Preprocessed counts data.
        bias : array of float, optional
            Biases computed by ICE normalization.
        inferring_alpha : bool, optional
            A value of "True" indicates that the current optimization aims to
            infer alpha, rather than the structure.

        Returns
        -------
        constraint_obj
            Loss for constraint.
        """
        pass


class BeadChainConnectivity2019(Constraint):
    """TODO"""

    def __init__(self, lambda_val, lengths, ploidy, multiscale_factor=1,
                 hparams=None, fullres_struct_nan=None, lowmem=False, mods=[]):
        self.abbrev = "bcc"
        self.name = "Bead-chain connectivity (2019)"
        self.during_alpha_infer = False
        self.lambda_val = lambda_val
        self.lengths = np.asarray(lengths)
        self.lengths_lowres = decrease_lengths_res(
            self.lengths, multiscale_factor=multiscale_factor)
        self.ploidy = ploidy
        self.multiscale_factor = multiscale_factor
        self.hparams = hparams
        self._fullres_struct_nan = None  # Not necessary for this constraint
        self._lowmem = lowmem
        self._var = None
        self.mods = mods  # TODO remove

        self.check()

    def check(self):
        if self.lambda_val < 0:
            raise ValueError("Constraint lambda may not be < 0.")
        if self.hparams is not None and len(self.hparams) > 0:
            raise ValueError(f"{self.name} constraint may not have hyperparams")

    def _setup(self, counts=None, bias=None):
        if self.lambda_val <= 0:
            return
        if self._var is not None:
            return self._var
        row_nghbr = _neighboring_bead_indices(
            lengths=self.lengths, ploidy=self.ploidy,
            multiscale_factor=self.multiscale_factor)
        var = {'row_nghbr': row_nghbr}
        if not self._lowmem:
            self._var = var
        return var

    def apply(self, struct, alpha=None, epsilon=None, counts=None, bias=None,
              inferring_alpha=False):
        if self.lambda_val == 0 or (
                inferring_alpha and not self.during_alpha_infer):
            return 0.
        var = self._setup(counts=counts, bias=bias)

        nghbr_dis = _euclidean_distance(
            struct, row=var['row_nghbr'], col=var['row_nghbr'] + 1)
        n_edges = nghbr_dis.shape[0]
        nghbr_dis_var = n_edges * ag_np.square(
            nghbr_dis).sum() / ag_np.square(nghbr_dis.sum())
        obj = nghbr_dis_var - 1.

        if ag_np.isnan(obj) or ag_np.isinf(obj):
            raise ValueError(f"{self.name} constraint objective is {obj}.")
        return self.lambda_val * obj


class HomologSeparating2019(Constraint):
    """TODO"""

    def __init__(self, lambda_val, lengths, ploidy, multiscale_factor=1,
                 hparams=None, fullres_struct_nan=None, lowmem=False, mods=[]):
        self.abbrev = "hsc"
        self.name = "Homolog separating (2019)"
        self.during_alpha_infer = False
        self.lambda_val = lambda_val
        self.lengths = np.asarray(lengths)
        self.lengths_lowres = decrease_lengths_res(
            self.lengths, multiscale_factor=multiscale_factor)
        self.ploidy = ploidy
        self.multiscale_factor = multiscale_factor
        self.hparams = hparams
        self._fullres_struct_nan = fullres_struct_nan  # For self._setup() only
        self._lowmem = lowmem
        self._var = None
        self.mods = mods  # TODO remove

        self.check()

    def check(self):
        if self.ploidy == 1 and self.lambda_val > 0:
            raise ValueError(f"{self.name} constraint can not be applied to"
                             " haploid genomes.")
        if self.lambda_val < 0:
            raise ValueError("Constraint lambda may not be < 0.")
        # Hyperparam: perc_diff
        if self.hparams is None:
            self.hparams = {'perc_diff': None}
        if 'perc_diff' not in self.hparams:
            self.hparams['perc_diff'] = None
        if self.hparams['perc_diff'] is not None and (
                self.hparams['perc_diff'] < 0 or self.hparams['perc_diff'] > 1):
            raise ValueError("'perc_diff' must be between 0 and 1.")
        # Hyperparam: est_hmlg_sep
        if 'est_hmlg_sep' not in self.hparams or self.hparams[
                'est_hmlg_sep'] is None:
            raise ValueError(f"{self.name} constraint is missing neccessary"
                             " hyperparams: 'est_hmlg_sep'")
        if isinstance(self.hparams['est_hmlg_sep'], list):
            self.hparams['est_hmlg_sep'] = np.array(
                self.hparams['est_hmlg_sep'])
        if not isinstance(
                self.hparams['est_hmlg_sep'], (np.ndarray, float, int)):
            raise ValueError(f"{self.name} constraint hyperparam 'est_hmlg_sep'"
                             " not understood.")
        if isinstance(self.hparams['est_hmlg_sep'], np.ndarray):
            if self.hparams['est_hmlg_sep'].size not in (1, self.lengths.size):
                raise ValueError(f"{self.name} constraint hyperparam"
                                 " 'est_hmlg_sep' is not the correct size.")

    def _setup(self, counts=None, bias=None):
        if self.lambda_val <= 0:
            return
        if self._var is not None:
            return self._var

        if self.multiscale_factor != 1:
            fullres_per_lowres_bead = _count_fullres_per_lowres_bead(
                multiscale_factor=self.multiscale_factor, lengths=self.lengths,
                ploidy=self.ploidy, fullres_struct_nan=self._fullres_struct_nan)
            bead_weights = fullres_per_lowres_bead / self.multiscale_factor  # FIXME is this correct????
        else:
            bead_weights = np.ones((self.lengths_lowres.sum() * self.ploidy,))
        struct_nan = find_beads_to_remove(
            counts, lengths=self.lengths, ploidy=self.ploidy,
            multiscale_factor=self.multiscale_factor)
        bead_weights[struct_nan] = 0.
        n = self.lengths_lowres.sum()
        begin = end = 0
        for i in range(len(self.lengths_lowres)):
            end = end + self.lengths_lowres[i]
            bead_weights[:n][begin:end] /= np.sum(
                bead_weights[:n][begin:end])
            bead_weights[n:][begin:end] /= np.sum(
                bead_weights[n:][begin:end])
            begin = end
        bead_weights = bead_weights.reshape(-1, 1)

        var = {'bead_weights': bead_weights}
        if not self._lowmem:
            self._var = var
            self._fullres_struct_nan = None  # No longer needed unless lowmem
        return var

    def apply(self, struct, alpha=None, epsilon=None, counts=None, bias=None,
              inferring_alpha=False):
        if self.lambda_val == 0 or (
                inferring_alpha and not self.during_alpha_infer):
            return 0.
        var = self._setup(counts=counts, bias=bias)

        # Get homolog separation
        struct_bw = struct * np.repeat(var['bead_weights'], 3, axis=1)
        n = self.lengths_lowres.sum()
        homo_sep = ag_np.zeros(self.lengths_lowres.shape)
        begin = end = 0
        for i in range(self.lengths_lowres.shape[0]):
            end = end + ag_np.int32(self.lengths_lowres[i])
            chrom1_mean = ag_np.sum(struct_bw[begin:end], axis=0)
            chrom2_mean = ag_np.sum(struct_bw[(n + begin):(n + end)], axis=0)
            homo_sep_i = ag_np.sqrt(ag_np.sum(ag_np.square(
                chrom1_mean - chrom2_mean)))
            homo_sep = homo_sep.at[i].set(homo_sep_i)
            begin = end

        homo_sep_diff = self.hparams["est_hmlg_sep"] - homo_sep
        if 'rscale' in self.mods:
            homo_sep_diff = 1 - homo_sep / self.hparams["est_hmlg_sep"]
        if self.hparams['perc_diff'] is None:
            homo_sep_diff = relu(homo_sep_diff)
            raise ValueError("I thought we weren't doing RELU for HSC anymore")
        else:
            hsc_cutoff = self.hparams['perc_diff'] * self.hparams[
                "est_hmlg_sep"]
            gt0 = homo_sep_diff > 0
            homo_sep_diff = homo_sep_diff.at[gt0].set(relu(
                homo_sep_diff[gt0] - hsc_cutoff))
            homo_sep_diff = homo_sep_diff.at[~gt0].set(-relu(
                -(homo_sep_diff[~gt0] + hsc_cutoff)))
        homo_sep_diff_sq = ag_np.square(homo_sep_diff)
        obj = ag_np.mean(homo_sep_diff_sq)

        if ag_np.isnan(obj) or ag_np.isinf(obj):
            raise ValueError(f"{self.name} constraint objective is {obj}.")
        return self.lambda_val * obj


class BeadChainConnectivity2021(Constraint):
    """TODO"""

    def __init__(self, lambda_val, lengths, ploidy, multiscale_factor=1,
                 hparams=None, fullres_struct_nan=None, lowmem=False, mods=[]):
        self.abbrev = "bcc"
        self.name = "Bead-chain connectivity (2021)"
        self.during_alpha_infer = True
        self.lambda_val = lambda_val
        self.lengths = np.asarray(lengths)
        self.lengths_lowres = decrease_lengths_res(
            self.lengths, multiscale_factor=multiscale_factor)
        self.ploidy = ploidy
        self.multiscale_factor = multiscale_factor
        self.hparams = hparams
        self._fullres_struct_nan = fullres_struct_nan  # For self._setup() only
        self._lowmem = lowmem
        self._var = None
        self.mods = mods  # TODO remove

        self.check()

    def check(self):
        if self.lambda_val < 0:
            raise ValueError("Constraint lambda may not be < 0.")
        if self.hparams is not None and len(self.hparams) > 0:
            raise ValueError(f"{self.name} constraint may not have hyperparams")

    def _setup(self, counts=None, bias=None):
        if self.lambda_val <= 0:
            return
        if self._var is not None:
            return self._var
        row_nghbr = _neighboring_bead_indices(
            lengths=self.lengths, ploidy=self.ploidy,
            multiscale_factor=self.multiscale_factor)

        counts = [c for c in counts if c.sum() != 0]
        beta = _ambiguate_beta(
            [c.beta for c in counts if c.sum() != 0], counts=counts,
            lengths=self.lengths, ploidy=self.ploidy)
        counts_ambig = ambiguate_counts(
            counts=counts, lengths=self.lengths, ploidy=self.ploidy,
            exclude_zeros=True)
        row_nghbr_ambig = _neighboring_bead_indices(
            lengths=self.lengths, ploidy=1,
            multiscale_factor=self.multiscale_factor, counts=counts_ambig,
            include_struct_nan_beads=False)

        if bias is not None and not np.all(bias == 1):
            raise NotImplementedError("Implement for bias")  # TODO

        counts_ambig = decrease_counts_res(
            counts_ambig, multiscale_factor=self.multiscale_factor,
            lengths=self.lengths, ploidy=self.ploidy)
        nghbr_counts = counts_ambig.diagonal(k=1)[row_nghbr_ambig] / self.ploidy
        if self.multiscale_factor > 1:
            fullres_per_lowres_bead = _count_fullres_per_lowres_bead(
                multiscale_factor=self.multiscale_factor, lengths=self.lengths,
                ploidy=1, fullres_struct_nan=self._fullres_struct_nan)
            raise NotImplementedError("Implement for multiscale")  # TODO

        var = {
            'row_nghbr': row_nghbr, 'beta': beta, 'nghbr_counts': nghbr_counts}
        if not self._lowmem:
            self._var = var
            self._fullres_struct_nan = None  # No longer needed unless lowmem
        return var

    def apply(self, struct, alpha=None, epsilon=None, counts=None, bias=None,
              inferring_alpha=False):
        if self.lambda_val == 0 or (
                inferring_alpha and not self.during_alpha_infer):
            return 0.
        elif alpha is None:
            raise ValueError(f"Must input alpha for {self.name} constraint.")
        var = self._setup(counts=counts, bias=bias)

        if (var['nghbr_counts'] == 0).sum() == 0:
            nghbr_dis = np.power(var['nghbr_counts'] / var['beta'], 1 / alpha)
            mu = nghbr_dis.mean()
            sigma_max = nghbr_dis.std()
        else:
            mu, sigma_max = taylor_approx_ndc(
                var['nghbr_counts'], beta=var['beta'], alpha=alpha, order=1)

        nghbr_dis = _euclidean_distance(
            struct, row=var['row_nghbr'], col=var['row_nghbr'] + 1)

        mad = ag_np.median(ag_np.absolute(
            nghbr_dis - ag_np.median(nghbr_dis)))
        sigma_tmp = 1.4826 * mad
        # sigma_tmp = ag_np.sqrt(ag_np.mean(ag_np.square(data - mu))) # old - i guess this didn't work

        if 'norm_dis_nomin' in self.mods:
            sigma = sigma_tmp
        else:
            sigma = relu_min(sigma_tmp, sigma_max)

        obj = ag_np.log(sigma) + ag_np.mean(
            ag_np.square(nghbr_dis - mu)) / (2 * ag_np.square(sigma))
        # if type(obj).__name__ == 'DeviceArray':
        #     data = nghbr_dis
        #     # TRUE:    μ=1.010   σMax=0.119      mean=1.004      sigma=0.098     sigma_tmp=0.098     std=0.098   obj=-1.8202
        #     # oldTRUE: μ=0.985     mean=1.004      sigma=0.098     std=0.098   obj=-1.8019
        #     # BCC1e1:         rmsd_intra=3.72   disterr_intra=39.9   disterr_interhmlg=70.8   ndv_nrmse=3.53  ()
        #     # norm_dis:       rmsd_intra=   disterr_intra=   disterr_interhmlg=   ndv_nrmse= ()
        #     # norm_dis_nomin: rmsd_intra=   disterr_intra=   disterr_interhmlg=   ndv_nrmse= ()
        #     print(f'μ={mu:.3f} \t σMax={sigma_max:.3f} \t mean={data.mean():.3f} \t sigma={sigma:.3f} \t sigma_tmp={sigma_tmp:.3f} \t std={data.std():.3f} \t obj={obj:.5g}')

        if ag_np.isnan(obj) or ag_np.isinf(obj):
            raise ValueError(f"{self.name} constraint objective is {obj}.")
        return self.lambda_val * obj


class BeadChainConnectivity2022(Constraint):
    """TODO"""

    def __init__(self, lambda_val, lengths, ploidy, multiscale_factor=1,
                 hparams=None, fullres_struct_nan=None, lowmem=False, mods=[]):
        self.abbrev = "bcc"
        self.name = "Bead-chain connectivity (2022)"
        self.during_alpha_infer = True
        self.lambda_val = lambda_val
        self.lengths = np.asarray(lengths)
        self.lengths_lowres = decrease_lengths_res(
            self.lengths, multiscale_factor=multiscale_factor)
        self.ploidy = ploidy
        self.multiscale_factor = multiscale_factor
        self.hparams = hparams
        self._fullres_struct_nan = None  # Not necessary for this constraint
        self._lowmem = lowmem
        self._var = None
        self.mods = mods  # TODO remove

        self.check()

    def check(self):
        if self.ploidy == 1 and self.lambda_val > 0:
            raise ValueError(f"{self.name} constraint can not be applied to"
                             " haploid genomes.")
        if self.lambda_val < 0:
            raise ValueError("Constraint lambda may not be < 0.")
        if self.hparams is None or 'counts_interchrom' not in self.hparams or (
                self.hparams['counts_interchrom'] is None):
            raise ValueError(f"{self.name} constraint is missing"
                             f" neccessary hyperparams: 'counts_interchrom'")

    def _setup(self, counts=None, bias=None):
        if self.lambda_val <= 0:
            return
        if self._var is not None:
            return self._var
        row_nghbr = _neighboring_bead_indices(
            lengths=self.lengths, ploidy=self.ploidy,
            multiscale_factor=self.multiscale_factor)

        if self.multiscale_factor > 1:
            raise NotImplementedError("or maybe it is implemented. who am i to say??")

        row_nghbr = _neighboring_bead_indices(
            lengths=self.lengths, ploidy=1,
            multiscale_factor=self.multiscale_factor)

        beta = _ambiguate_beta(
            [c.beta for c in counts if c.sum() != 0], counts=counts,
            lengths=self.lengths, ploidy=self.ploidy)
        counts = [c for c in counts if c.sum() != 0]
        counts_ambig = ambiguate_counts(
            counts=counts, lengths=self.lengths, ploidy=2, exclude_zeros=False)
        counts_nghbr = counts_ambig[row_nghbr, row_nghbr + 1]
        counts_nghbr[np.isnan(counts_nghbr)] = np.nanmean(counts_nghbr)

        if bias is None or np.all(bias == 1):
            bias_nghbr = 1
        else:
            bias_nghbr = bias.ravel()[row_nghbr] * bias.ravel()[row_nghbr + 1]

        var = {
            'row_nghbr': row_nghbr, 'counts_nghbr': counts_nghbr,
            'bias_nghbr': bias_nghbr, 'beta': beta}
        if not self._lowmem:
            self._var = var
        return var

    def apply(self, struct, alpha=None, epsilon=None, counts=None, bias=None,
              inferring_alpha=False):
        if self.lambda_val == 0 or (
                inferring_alpha and not self.during_alpha_infer):
            return 0.
        elif alpha is None:
            raise ValueError(f"Must input alpha for {self.name} constraint.")
        var = self._setup(counts=counts, bias=bias)

        nghbr_dis = _euclidean_distance(
            struct, row=var['row_nghbr'], col=var['row_nghbr'] + 1)
        lambda_nghbr = var['beta'] * var['bias_nghbr'] * ag_np.power(
            nghbr_dis, alpha)
        if 'lenient' in self.mods:
            obj = poisson_nll(
                var['counts_nghbr'],
                lambda_pois=2 * (lambda_nghbr + lambda_nghbr_inter))
        else:
            data = np.maximum(
                0, var['counts_nghbr'] - self.hparams['counts_interchrom'] / 2)
            obj = poisson_nll(np.tile(data, 2), lambda_pois=2 * lambda_nghbr)

        if ag_np.isnan(obj) or ag_np.isinf(obj):
            raise ValueError(f"{self.name} constraint objective is {obj}.")
        return self.lambda_val * obj


class HomologSeparating2022(Constraint):
    """TODO"""

    def __init__(self, lambda_val, lengths, ploidy, multiscale_factor=1,
                 hparams=None, fullres_struct_nan=None, lowmem=False, mods=[]):
        self.abbrev = "hsc"
        self.name = "Homolog separating (2022)"
        self.during_alpha_infer = True
        self.lambda_val = lambda_val
        self.lengths = np.asarray(lengths)
        self.lengths_lowres = decrease_lengths_res(
            self.lengths, multiscale_factor=multiscale_factor)
        self.ploidy = ploidy
        self.multiscale_factor = multiscale_factor
        self.hparams = hparams
        self._fullres_struct_nan = None  # Not necessary for this constraint
        self._lowmem = lowmem
        self._var = None
        self.mods = mods  # TODO remove

        self.check()

    def check(self):
        if self.ploidy == 1 and self.lambda_val > 0:
            raise ValueError(f"{self.name} constraint can not be applied to"
                             " haploid genomes.")
        if self.lambda_val < 0:
            raise ValueError("Constraint lambda may not be < 0.")
        if self.hparams is None or 'counts_interchrom' not in self.hparams or (
                self.hparams['counts_interchrom'] is None):
            raise ValueError(f"{self.name} constraint is missing"
                             f" neccessary hyperparams: 'counts_interchrom'")

    def _setup(self, counts=None, bias=None):
        if self.lambda_val <= 0:
            return
        if self._var is not None:
            return self._var

        beta = _ambiguate_beta(
            [c.beta for c in counts if c.sum() != 0], counts=counts,
            lengths=self.lengths, ploidy=self.ploidy)

        var = {'beta': beta}
        if not self._lowmem:
            self._var = var
        return var

    def apply(self, struct, alpha=None, epsilon=None, counts=None, bias=None,
              inferring_alpha=False):
        if self.lambda_val == 0 or (
                inferring_alpha and not self.during_alpha_infer):
            return 0.
        elif alpha is None:
            raise ValueError(f"Must input alpha for {self.name} constraint.")
        var = self._setup(counts=counts, bias=bias)

        n = int(struct.shape[0] / 2)
        # TODO should I exclude NaN beads?
        row, col = (x.flatten() for x in np.indices((n, n)))
        # if 'trim_inter' in self.mods:
        #     mask_inter_nghbr = ((col == row + 1) & np.isin(
        #         row, row_nghbr_h1)) | ((col + 1 == row) & np.isin(
        #         col, row_nghbr_h1))
        #     row = row[~mask_inter_nghbr]
        #     col = col[~mask_inter_nghbr]
        dis_interhmlg = _euclidean_distance(struct, row=row, col=col + n)
        if bias is None or np.all(bias == 1):
            bias_interhmlg = 1
        else:
            bias_interhmlg = bias.ravel()[row] * bias.ravel()[col]
        dis_alpha_interhmlg = ag_np.power(dis_interhmlg, alpha)

        if 'sum2' in self.mods:
            dis_alpha_interhmlg = dis_alpha_interhmlg.reshape(n, n)
            dis_alpha_interhmlg = dis_alpha_interhmlg[ag_np.triu_indices(
                n, 1)] + dis_alpha_interhmlg[ag_np.tril_indices(n, -1)]
            lambda_interhmlg = 2 * var['beta'] * (
                bias_interhmlg * dis_alpha_interhmlg)
        else:
            lambda_interhmlg = 4 * var['beta'] * (
                bias_interhmlg * dis_alpha_interhmlg)

        if 'mean' in self.mods:
            # TODO would have to apply to each pair of molecules separately
            lambda_interhmlg = ag_np.mean(lambda_interhmlg)

        if 'nbinom' in self.mods:
            gamma_mean = lambda_interhmlg
            gamma_var = np.mean([
                self.hparams['counts_interchrom'].mean(),
                self.hparams['counts_interchrom'].var()])  # TODO check
            theta = gamma_var / gamma_mean
            k = ag_np.square(gamma_mean) / gamma_var

            obj = gamma_poisson_nll(
                theta=theta, k=k,
                data=(self.hparams['counts_interchrom']).reshape(1, -1))
            raise NotImplementedError
        else:
            obj = poisson_nll(
                self.hparams['counts_interchrom'], lambda_pois=lambda_interhmlg)

        # print((self.hparams['counts_interchrom'], lambda_interhmlg, obj), flush=True)

        # num_nghbr_hmlg = int(var['row_nghbr'].size / 2)
        # row_nghbr_h1 = var['row_nghbr'][:num_nghbr_hmlg]
        # row_nghbr_h2 = var['row_nghbr'][num_nghbr_hmlg:]
        # dis_nghbr_h1h2 = _euclidean_distance(
        #     struct, row=row_nghbr_h1, col=row_nghbr_h2 + 1)
        # dis_nghbr_h2h1 = _euclidean_distance(
        #     struct, row=row_nghbr_h2, col=row_nghbr_h1 + 1)
        # lambda_nghbr_inter = var['beta'] * var['bias_nghbr'] * (
        #     ag_np.power(dis_nghbr_h1h2, alpha) + ag_np.power(
        #         dis_nghbr_h2h1, alpha))
        # obj_nghbr_inter = poisson_nll(
        #     self.hparams['counts_interchrom'],
        #     lambda_pois=2 * ag_np.mean(lambda_nghbr_inter))

        if ag_np.isnan(obj) or ag_np.isinf(obj):
            raise ValueError(f"{self.name} constraint objective is {obj}.")
        return self.lambda_val * obj


def prep_constraints(counts, lengths, ploidy, multiscale_factor=1,
                     bcc_lambda=0., hsc_lambda=0., bcc_version='2019',
                     hsc_version='2019', counts_interchrom=None,
                     est_hmlg_sep=None, hsc_perc_diff=None,
                     fullres_struct_nan=None, verbose=True, mods=[]):
    """TODO"""

    # TODO remove
    if mods is None:
        mods = []
    elif isinstance(mods, str):
        mods = mods.lower().split('.')
    else:
        mods = [x.lower() for x in mods]

    if bcc_version is None:
        bcc_version = '2019'
    bcc_version = str(bcc_version)
    if hsc_version is None:
        hsc_version = '2019'
    hsc_version = str(hsc_version)

    if counts_interchrom is None and ((
            bcc_lambda != 0 and bcc_version == '2022') or (
            hsc_lambda != 0 and hsc_version == '2022')):
        counts_interchrom = get_fullres_counts_interchrom(
            counts, lengths=lengths, ploidy=ploidy,
            multiscale_factor=multiscale_factor, mods=mods)

    bcc_class = {
        '2019': BeadChainConnectivity2019, '2021': BeadChainConnectivity2021,
        '2022': BeadChainConnectivity2022}
    hsc_class = {
        '2019': HomologSeparating2019, '2022': HomologSeparating2022}
    bcc_hparams = {
        '2019': None, '2021': None,
        '2022': {'counts_interchrom': counts_interchrom}}
    hsc_hparams = {
        '2019': {'est_hmlg_sep': est_hmlg_sep, 'perc_diff': hsc_perc_diff},
        '2022': {'counts_interchrom': counts_interchrom}}

    constraints = []
    if bcc_lambda != 0:
        constraints.append(bcc_class[bcc_version](
            bcc_lambda, lengths=lengths, ploidy=ploidy,
            multiscale_factor=multiscale_factor,
            hparams=bcc_hparams[bcc_version],
            fullres_struct_nan=fullres_struct_nan, lowmem=False, mods=mods))
    if hsc_lambda != 0:
        constraints.append(hsc_class[hsc_version](
            hsc_lambda, lengths=lengths, ploidy=ploidy,
            multiscale_factor=multiscale_factor,
            hparams=hsc_hparams[hsc_version],
            fullres_struct_nan=fullres_struct_nan, lowmem=False, mods=mods))

    # TODO have var=None input to Constraint._setup = share var dict for all (only add to var if not already found)
    # TODO if NOT lowmem, run Constraint._setup method here = share var dict for all

    # TODO have var=None input to Constraint.apply = share var dict for all during opt if lowmem
    # TODO if lowmem, run Constraint._setup before .apply during opt = share var dict for all during opt if lowmem

    return constraints


def get_fullres_counts_interchrom(counts, lengths, ploidy, mods=[]):
    if lengths.size == 1:
        raise ValueError(
            "Must input counts_interchrom if inferring single chromosome.")
    counts_ambig = ambiguate_counts(
        counts=counts, lengths=lengths, ploidy=ploidy, exclude_zeros=False)
    counts_interchrom = _inter_counts(
        counts_ambig, lengths, ploidy=ploidy, exclude_zeros=False)
    counts_interchrom = counts_interchrom[~np.isnan(counts_interchrom)]
    if 'nbinom' in mods:
        return counts_interchrom
    else:
        return counts_interchrom.mean()


def taylor_approx_ndc(x, beta=1, alpha=-3, order=1):
    x = x / beta
    x_mean = np.mean(x)
    x_var = np.var(x)

    fx_mean = np.power(x_mean, 1 / alpha)
    fx_var = 1 / np.power(alpha, 2) * np.power(
        x_mean, (2 - 2 * alpha) / alpha) * x_var

    if order == 2:  # FIXME TODO
        tmp = (1 - alpha) / (2 * np.square(alpha)) * np.power(
            x_mean, (1 - 2 * alpha) / alpha)
        fx_mean = fx_mean + tmp * x_var
        fx_var = fx_var + np.square(tmp) * (np.var(
            np.square(x)) - 4 * np.square(x_mean) * x_var)

    fx_std = np.sqrt(fx_var)
    return fx_mean, fx_std


def _neighboring_bead_indices(lengths, ploidy, multiscale_factor=1,
                              counts=None, include_struct_nan_beads=True):
    """Return row & col of neighboring beads, along a homolog of a chromosome.
    """

    lengths_lowres = decrease_lengths_res(lengths, multiscale_factor)
    nbeads = lengths_lowres.sum() * ploidy

    row_nghbr = np.arange(nbeads - 1, dtype=int)

    # Optionally remove beads for which there is no counts data
    if not include_struct_nan_beads:
        if counts is None:
            raise ValueError(
                "Counts must be inputted if including struct_nan beads.")
        struct_nan = find_beads_to_remove(
            counts, lengths=lengths, ploidy=ploidy,
            multiscale_factor=multiscale_factor)
        nghbr_dis_mask = (~np.isin(row_nghbr, struct_nan)) & (
            ~np.isin(row_nghbr + 1, struct_nan))
        row_nghbr = row_nghbr[nghbr_dis_mask]

    # Remove if "neighbor" beads are actually on different chromosomes
    # or homologs
    bins = np.tile(lengths_lowres, ploidy).cumsum()
    same_bin = np.digitize(row_nghbr, bins) == np.digitize(row_nghbr + 1, bins)

    row_nghbr = row_nghbr[same_bin]

    return row_nghbr


def _inter_homolog_dis(struct, lengths):
    """Computes distance between homologs for a normal diploid structure.
    """

    struct = struct.copy().reshape(-1, 3)

    n = int(struct.shape[0] / 2)
    homo1 = struct[:n, :]
    homo2 = struct[n:, :]

    homo_dis = []
    begin = end = 0
    for i in range(lengths.size):
        end += lengths[i]
        if np.isnan(homo1[begin:end, 0]).sum() == lengths[i] or np.isnan(
                homo2[begin:end, 0]).sum() == lengths[i]:
            homo_dis.append(np.nan)
        else:
            homo_dis.append(((np.nanmean(homo1[
                begin:end, :], axis=0) - np.nanmean(
                homo2[begin:end, :], axis=0)) ** 2).sum() ** 0.5)
        begin = end

    homo_dis = np.array(homo_dis)
    homo_dis[np.isnan(homo_dis)] = np.nanmean(homo_dis)

    return homo_dis


def _inter_homolog_dis_via_simple_diploid(struct, lengths):
    """Computes distance between chromosomes for a faux-haploid structure.
    """

    from sklearn.metrics import euclidean_distances

    struct = struct.copy().reshape(-1, 3)

    chrom_barycenters = []
    begin = end = 0
    for i in range(lengths.size):
        end += lengths[i]
        if np.isnan(struct[begin:end, 0]).sum() < lengths[i]:
            chrom_barycenters.append(
                np.nanmean(struct[begin:end, :], axis=0).reshape(1, 3))
        begin = end

    chrom_barycenters = np.concatenate(chrom_barycenters)

    homo_dis = euclidean_distances(chrom_barycenters)
    homo_dis[np.tril_indices(homo_dis.shape[0])] = np.nan

    return np.full(lengths.shape, np.nanmean(homo_dis))


def distance_between_homologs(structures, lengths, mixture_coefs=None,
                              simple_diploid=False):
    """Computes distances between homologs for a given structure.

    For diploid organisms, this computes the distance between homolog centers
    of mass for each chromosome.

    Parameters
    ----------
    structures : array of float or list of array of float
        3D chromatin structure(s) for which to assess inter-homolog distances.
    lengths : array_like of int
        Number of beads per homolog of each chromosome.
    simple_diploid: bool, optional
        For diploid organisms: whether the structure is an inferred "simple
        diploid" structure in which homologs are assumed to be identical and
        completely overlapping with one another.

    Returns
    -------
    array of float
        Distance between homologs per chromosome.

    """

    from .utils_poisson import _format_structures

    structures = _format_structures(
        structures=structures, lengths=lengths,
        ploidy=(1 if simple_diploid else 2),
        mixture_coefs=mixture_coefs)

    homo_dis = []
    for struct in structures:
        if simple_diploid:
            homo_dis.append(_inter_homolog_dis_via_simple_diploid(
                struct=struct, lengths=lengths))
        else:
            homo_dis.append(_inter_homolog_dis(struct=struct, lengths=lengths))

    return np.mean(homo_dis, axis=0)
