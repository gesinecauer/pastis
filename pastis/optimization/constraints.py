import sys

if sys.version_info[0] < 3:
    raise Exception("Must be using Python 3")

import numpy as np
import re

from .utils_poisson import _setup_jax
_setup_jax()
import jax.numpy as ag_np
from jax.nn import relu
from jax.scipy.stats.gamma import logpdf as logpdf_gamma
from jax.scipy.stats.norm import logpdf as logpdf_norm
from jax.scipy.stats.nbinom import logpmf as logpmf_negbinom
from jax.scipy.special import gammaln

from .multiscale_optimization import decrease_lengths_res, decrease_counts_res
from .multiscale_optimization import _count_fullres_per_lowres_bead
from .multiscale_optimization import _group_counts_multiscale
from .utils_poisson import find_beads_to_remove, _euclidean_distance
from .utils_poisson import relu_min, relu_max
from .utils_poisson import _inter_counts, _counts_near_diag, _intra_mask
from .counts import ambiguate_counts, _ambiguate_beta
from .likelihoods import poisson_nll, gamma_poisson_nll
from .poisson import get_gamma_moments
from ..io.read import load_data


class Constraint(object):
    """Compute loss for the given constraint.

    Prepares cand computes the loss function for the given constraint.

    Parameters
    ----------
    lambda_val : float
        Lambda that specifies how strongly constraint is applied during
        calculation of the entire objective.
    lengths : array_like of int
        Number of beads per homolog of each chromosome.
    ploidy : {1, 2}
        Ploidy, 1 indicates haploid, 2 indicates diploid.
    multiscale_factor : int, optional
        Factor by which to reduce the resolution. A value of 2 halves the
        resolution. A value of 1 indicates full resolution.
    hparams : dict, optional
        Any hyperparameters used for the calculation of constraint.

    Attributes
    ----------
    abbrev : str
        Three-letter abbreviation for constraint name.
    name : str
        Full name of constraint
    during_alpha_infer : bool
        Whether or not this constraint should be computed during inference of
        alpha.
    lambda_val : float
        Lambda that specifies how strongly constraint is applied during
        calculation of the entire objective.
    lengths : array_like of int
        Number of beads per homolog of each chromosome.
    ploidy : {1, 2}
        Ploidy, 1 indicates haploid, 2 indicates diploid.
    multiscale_factor : int, optional
        Factor by which to reduce the resolution. A value of 2 halves the
        resolution. A value of 1 indicates full resolution.
    hparams : dict, optional
        Any hyperparameters used for the calculation of constraint.
    fullres_struct_nan : array of int
        Beads that should be removed (set to NaN) in the full-res structure.
    lowmem : bool, optional
        Whether variables generated by _setup should be saved for subsequent
        iterations.
    """

    def __init__(self, lambda_val, lengths, ploidy, multiscale_factor=1,
                 hparams=None, fullres_struct_nan=None, lowmem=False, mods=[]):
        self.abbrev = None
        self.name = None
        self.during_alpha_infer = None
        self.lambda_val = lambda_val
        self.lengths = lengths
        self.ploidy = ploidy
        self.multiscale_factor = multiscale_factor
        self.hparams = hparams
        self._fullres_struct_nan = fullres_struct_nan  # For self._setup() only
        self._lowmem = lowmem
        self._var = None

    def __str__(self):
        out = [f"CONSTRAINT: {self.name},  LAMBDA={self.lambda_val:g}"]
        if self.hparams is None:
            return "\n".join(out)
        for name, val in self.hparams.items():
            label = f"\t\t\t{name} = "
            if isinstance(val, (np.ndarray, list)):
                out.append(label + np.array2string(
                    val, formatter={'float_kind': lambda x: "%.3g" % x},
                    prefix=" " * len(label), separator=", "))
            elif isinstance(val, float):
                out.append(f"{label}{val:g}")
            else:
                out.append(f"{label}{val}")
        return "\n".join(out)

    def check(self):
        """Check constraints object.

        Check that lambdas are greater than zero, and that necessary
        hyperparameters are supplied."""
        pass

    def _setup(self, counts=None, bias=None):
        """Set up for applying constraint (not specific to inferred params)"""
        pass

    def apply(self, struct, alpha=None, epsilon=None, counts=None, bias=None,
              inferring_alpha=False):

        """Apply constraint using given structure(s).

        Compute loss for the given constraint.

        Parameters
        ----------
        struct : ndarray
            3D chromatin structure(s) for which to compute the constraint.
        alpha : float
            Biophysical parameter of the transfer function used in converting
            counts to wish distances. If alpha is not specified, it will be
            inferred.
        epsilon : float, optional
            TODO
        counts : list of CountsMatrix subclass instances
            Preprocessed counts data.
        bias : array of float, optional
            Biases computed by ICE normalization.
        inferring_alpha : bool, optional
            A value of "True" indicates that the current optimization aims to
            infer alpha, rather than the structure.

        Returns
        -------
        constraint_obj
            Loss for constraint.
        """
        pass


class BeadChainConnectivity2019(Constraint):
    """TODO"""

    def __init__(self, lambda_val, lengths, ploidy, multiscale_factor=1,
                 hparams=None, fullres_struct_nan=None, lowmem=False, mods=[]):
        self.abbrev = "bcc"
        self.name = "Bead-chain connectivity (2019)"
        self.during_alpha_infer = False
        self.lambda_val = lambda_val
        self.lengths = np.asarray(lengths)
        self.lengths_lowres = decrease_lengths_res(
            self.lengths, multiscale_factor=multiscale_factor)
        self.ploidy = ploidy
        self.multiscale_factor = multiscale_factor
        self.hparams = hparams
        self._fullres_struct_nan = None  # Not necessary for this constraint
        self._lowmem = lowmem
        self._var = None
        self.mods = mods  # TODO remove

        self.check()

    def check(self):
        if self.lambda_val < 0:
            raise ValueError("Constraint lambda may not be < 0.")
        if self.hparams is not None and len(self.hparams) > 0:
            raise ValueError(f"{self.name} constraint may not have hyperparams")

    def _setup(self, counts=None, bias=None):
        if self.lambda_val <= 0:
            return
        if self._var is not None:
            return self._var
        row_nghbr = _neighboring_bead_indices(
            lengths=self.lengths, ploidy=self.ploidy,
            multiscale_factor=self.multiscale_factor)
        var = {'row_nghbr': row_nghbr}
        if not self._lowmem:
            self._var = var
        return var

    def apply(self, struct, alpha=None, epsilon=None, counts=None, bias=None,
              inferring_alpha=False):
        if self.lambda_val == 0 or (
                inferring_alpha and not self.during_alpha_infer):
            return 0.
        var = self._setup(counts=counts, bias=bias)

        nghbr_dis = _euclidean_distance(
            struct, row=var['row_nghbr'], col=var['row_nghbr'] + 1)
        n_edges = nghbr_dis.shape[0]
        nghbr_dis_var = n_edges * ag_np.square(
            nghbr_dis).sum() / ag_np.square(nghbr_dis.sum())
        obj = nghbr_dis_var - 1.

        if not ag_np.isfinite(obj):

            # if type(obj).__name__ in ('DeviceArray', 'ndarray'):
            print(f"{struct.mean()=:.3g}")  # TODO remove
            print(f"{np.isnan(struct).sum() / struct.size:.3g}")
            print(f"{nghbr_dis.mean()=:.3g}")
            print(f"{nghbr_dis.min()=:.3g}")
            print(f"{nghbr_dis_var.mean()=:.3g}")
            exit(1)

            raise ValueError(f"{self.name} constraint is {obj}.")
        return self.lambda_val * obj


class HomologSeparating2019(Constraint):
    """TODO"""

    def __init__(self, lambda_val, lengths, ploidy, multiscale_factor=1,
                 hparams=None, fullres_struct_nan=None, lowmem=False, mods=[]):
        self.abbrev = "hsc"
        self.name = "Homolog separating (2019)"
        self.during_alpha_infer = False
        self.lambda_val = lambda_val
        self.lengths = np.asarray(lengths)
        self.lengths_lowres = decrease_lengths_res(
            self.lengths, multiscale_factor=multiscale_factor)
        self.ploidy = ploidy
        self.multiscale_factor = multiscale_factor
        self.hparams = hparams
        self._fullres_struct_nan = fullres_struct_nan  # For self._setup() only
        self._lowmem = lowmem
        self._var = None
        self.mods = mods  # TODO remove

        self.check()

    def check(self):
        if self.ploidy == 1 and self.lambda_val > 0:
            raise ValueError(f"{self.name} constraint can not be applied to"
                             " haploid genomes.")
        if self.lambda_val < 0:
            raise ValueError("Constraint lambda may not be < 0.")
        # Hyperparam: perc_diff
        if self.hparams is None:
            self.hparams = {'perc_diff': None}
        if 'perc_diff' not in self.hparams:
            self.hparams['perc_diff'] = None
        if self.hparams['perc_diff'] is not None and (
                self.hparams['perc_diff'] < 0 or self.hparams['perc_diff'] > 1):
            raise ValueError("'perc_diff' must be between 0 and 1.")
        # Hyperparam: est_hmlg_sep
        if 'est_hmlg_sep' not in self.hparams or self.hparams[
                'est_hmlg_sep'] is None:
            raise ValueError(f"{self.name} constraint is missing neccessary"
                             " hyperparams: 'est_hmlg_sep'")
        if isinstance(self.hparams['est_hmlg_sep'], list):
            self.hparams['est_hmlg_sep'] = np.array(
                self.hparams['est_hmlg_sep'])
        if not isinstance(
                self.hparams['est_hmlg_sep'], (np.ndarray, float, int)):
            raise ValueError(f"{self.name} constraint hyperparam 'est_hmlg_sep'"
                             " not understood.")
        if isinstance(self.hparams['est_hmlg_sep'], np.ndarray):
            if self.hparams['est_hmlg_sep'].size not in (1, self.lengths.size):
                raise ValueError(f"{self.name} constraint hyperparam"
                                 " 'est_hmlg_sep' is not the correct size.")

    def _setup(self, counts=None, bias=None):
        if self.lambda_val <= 0:
            return
        if self._var is not None:
            return self._var

        if self.multiscale_factor > 1:
            fullres_per_lowres_bead = _count_fullres_per_lowres_bead(
                multiscale_factor=self.multiscale_factor, lengths=self.lengths,
                ploidy=self.ploidy, fullres_struct_nan=self._fullres_struct_nan)
            bead_weights = fullres_per_lowres_bead / self.multiscale_factor  # FIXME is this correct????
        else:
            bead_weights = np.ones((self.lengths_lowres.sum() * self.ploidy,))
        struct_nan = find_beads_to_remove(
            counts, lengths=self.lengths, ploidy=self.ploidy,
            multiscale_factor=self.multiscale_factor)
        if struct_nan.size != 0:
            raise ValueError("Check that we actually want to remove torm beads here...")
        bead_weights[struct_nan] = 0.
        n = self.lengths_lowres.sum()
        begin = end = 0
        for i in range(len(self.lengths_lowres)):
            end = end + self.lengths_lowres[i]
            bead_weights[begin:end] /= np.sum(bead_weights[begin:end])
            bead_weights[n + begin:n + end] /= np.sum(
                bead_weights[n + begin:n + end])
            begin = end
        bead_weights = bead_weights.reshape(-1, 1)

        var = {'bead_weights': bead_weights}
        if not self._lowmem:
            self._var = var
            self._fullres_struct_nan = None  # No longer needed unless lowmem
        return var

    def apply(self, struct, alpha=None, epsilon=None, counts=None, bias=None,
              inferring_alpha=False):
        if self.lambda_val == 0 or (
                inferring_alpha and not self.during_alpha_infer):
            return 0.
        var = self._setup(counts=counts, bias=bias)

        # Get homolog separation
        struct_bw = struct * np.repeat(var['bead_weights'], 3, axis=1)
        n = self.lengths_lowres.sum()
        hmlg_sep = ag_np.zeros(self.lengths_lowres.shape)
        begin = end = 0
        for i in range(self.lengths_lowres.size):
            end = end + ag_np.int32(self.lengths_lowres[i])
            chrom1_mean = ag_np.sum(struct_bw[begin:end], axis=0)
            chrom2_mean = ag_np.sum(struct_bw[(n + begin):(n + end)], axis=0)
            hmlg_sep_i = ag_np.sqrt(ag_np.sum(ag_np.square(
                chrom1_mean - chrom2_mean)))
            hmlg_sep = hmlg_sep.at[i].set(hmlg_sep_i)
            begin = end

        hmlg_sep_diff = self.hparams["est_hmlg_sep"] - hmlg_sep
        if 'rscale' in self.mods:
            hmlg_sep_diff = 1 - hmlg_sep / self.hparams["est_hmlg_sep"]
        if self.hparams['perc_diff'] is None:
            hmlg_sep_diff = relu(hmlg_sep_diff)
            raise ValueError("I thought we weren't doing RELU for HSC anymore")
        else:
            hsc_cutoff = ag_np.array(self.hparams['perc_diff'] * self.hparams[
                "est_hmlg_sep"])
            gt0 = hmlg_sep_diff > 0
            hmlg_sep_diff = hmlg_sep_diff.at[gt0].set(relu(
                hmlg_sep_diff[gt0] - hsc_cutoff[gt0]))
            hmlg_sep_diff = hmlg_sep_diff.at[~gt0].set(-relu(
                -(hmlg_sep_diff[~gt0] + hsc_cutoff[~gt0])))
        hmlg_sep_diff_sq = ag_np.square(hmlg_sep_diff)
        obj = ag_np.mean(hmlg_sep_diff_sq)

        if not ag_np.isfinite(obj):
            raise ValueError(f"{self.name} constraint is {obj}.")
        return self.lambda_val * obj


class BeadChainConnectivity2021(Constraint):
    """TODO"""

    def __init__(self, lambda_val, lengths, ploidy, multiscale_factor=1,
                 hparams=None, fullres_struct_nan=None, lowmem=False, mods=[]):
        self.abbrev = "bcc"
        self.name = "Bead-chain connectivity (2021)"
        self.during_alpha_infer = True
        self.lambda_val = lambda_val
        self.lengths = np.asarray(lengths)
        self.lengths_lowres = decrease_lengths_res(
            self.lengths, multiscale_factor=multiscale_factor)
        self.ploidy = ploidy
        self.multiscale_factor = multiscale_factor
        self.hparams = hparams
        self._fullres_struct_nan = fullres_struct_nan  # For self._setup() only
        self._lowmem = lowmem
        self._var = None
        self.mods = mods  # TODO remove

        self.check()

    def check(self):
        if self.lambda_val < 0:
            raise ValueError("Constraint lambda may not be < 0.")
        if self.hparams is not None and len(self.hparams) > 0:
            raise ValueError(f"{self.name} constraint may not have hyperparams")

    def _setup(self, counts=None, bias=None):
        if self.lambda_val <= 0:
            return
        if self._var is not None:
            return self._var
        row_nghbr = _neighboring_bead_indices(
            lengths=self.lengths, ploidy=self.ploidy,
            multiscale_factor=self.multiscale_factor)

        beta = _ambiguate_beta(
            [c.beta for c in counts if c.sum() != 0], counts=counts,
            lengths=self.lengths, ploidy=self.ploidy)
        counts_ambig = ambiguate_counts(
            counts=counts, lengths=self.lengths, ploidy=self.ploidy,
            exclude_zeros=True)
        row_nghbr_ambig = _neighboring_bead_indices(
            lengths=self.lengths, ploidy=1,
            multiscale_factor=self.multiscale_factor, counts=counts_ambig,
            include_struct_nan_beads=False)

        if bias is not None and not np.all(bias == 1):
            raise NotImplementedError("Implement for bias... especially for multires")  # TODO

        counts_ambig = decrease_counts_res(
            counts_ambig, multiscale_factor=self.multiscale_factor,
            lengths=self.lengths, ploidy=self.ploidy)
        nghbr_counts = counts_ambig.diagonal(k=1)[row_nghbr_ambig] / self.ploidy
        if self.multiscale_factor > 1:
            fullres_per_lowres_bead = _count_fullres_per_lowres_bead(
                multiscale_factor=self.multiscale_factor, lengths=self.lengths,
                ploidy=1, fullres_struct_nan=self._fullres_struct_nan)
            raise NotImplementedError("Implement for multiscale")  # TODO

        var = {
            'row_nghbr': row_nghbr, 'beta': beta, 'nghbr_counts': nghbr_counts}
        if not self._lowmem:
            self._var = var
            self._fullres_struct_nan = None  # No longer needed unless lowmem
        return var

    def apply(self, struct, alpha=None, epsilon=None, counts=None, bias=None,
              inferring_alpha=False):
        if self.lambda_val == 0 or (
                inferring_alpha and not self.during_alpha_infer):
            return 0.
        elif alpha is None:
            raise ValueError(f"Must input alpha for {self.name} constraint.")
        var = self._setup(counts=counts, bias=bias)

        if (var['nghbr_counts'] == 0).sum() == 0:
            nghbr_dis = np.power(var['nghbr_counts'] / var['beta'], 1 / alpha)
            mu = nghbr_dis.mean()
            sigma_max = nghbr_dis.std()
        else:
            mu, sigma_max = taylor_approx_ndc(
                var['nghbr_counts'], beta=var['beta'], alpha=alpha, order=1)

        nghbr_dis = _euclidean_distance(
            struct, row=var['row_nghbr'], col=var['row_nghbr'] + 1)

        mad = ag_np.median(ag_np.absolute(
            nghbr_dis - ag_np.median(nghbr_dis)))
        sigma_tmp = 1.4826 * mad
        # sigma_tmp = ag_np.sqrt(ag_np.mean(ag_np.square(data - mu))) # old - i guess this didn't work

        if 'norm_dis_nomin' in self.mods:
            sigma = sigma_tmp
        else:
            sigma = relu_min(sigma_tmp, sigma_max)

        obj = ag_np.log(sigma) + ag_np.mean(
            ag_np.square(nghbr_dis - mu)) / (2 * ag_np.square(sigma))
        # if type(obj).__name__ == 'DeviceArray':
        #     data = nghbr_dis
        #     # TRUE:    Œº=1.010   œÉMax=0.119      mean=1.004      sigma=0.098     sigma_tmp=0.098     std=0.098   obj=-1.8202
        #     # oldTRUE: Œº=0.985     mean=1.004      sigma=0.098     std=0.098   obj=-1.8019
        #     # BCC1e1:         rmsd_intra=3.72   disterr_intra=39.9   disterr_interhmlg=70.8   ndv_nrmse=3.53  ()
        #     # norm_dis:       rmsd_intra=   disterr_intra=   disterr_interhmlg=   ndv_nrmse= ()
        #     # norm_dis_nomin: rmsd_intra=   disterr_intra=   disterr_interhmlg=   ndv_nrmse= ()
        #     print(f'Œº={mu:.3f} \t œÉMax={sigma_max:.3f} \t mean={data.mean():.3f} \t sigma={sigma:.3f} \t sigma_tmp={sigma_tmp:.3f} \t std={data.std():.3f} \t obj={obj:.5g}')

        if not ag_np.isfinite(obj):
            raise ValueError(f"{self.name} constraint is {obj}.")
        return self.lambda_val * obj


class BeadChainConnectivity2022(Constraint):
    """TODO"""

    def __init__(self, lambda_val, lengths, ploidy, multiscale_factor=1,
                 hparams=None, fullres_struct_nan=None, lowmem=False, mods=[]):
        self.abbrev = "bcc"
        self.name = "Bead-chain connectivity (2022)"
        self.during_alpha_infer = True
        self.lambda_val = lambda_val
        self.lengths = np.asarray(lengths)
        self.lengths_lowres = decrease_lengths_res(
            self.lengths, multiscale_factor=multiscale_factor)
        self.ploidy = ploidy
        self.multiscale_factor = multiscale_factor
        self.hparams = hparams
        self._fullres_struct_nan = fullres_struct_nan  # For self._setup() only
        self._lowmem = lowmem
        self._var = None
        self.mods = mods  # TODO remove

        self.check()

    def check(self):
        if self.ploidy == 1 and self.lambda_val > 0:
            raise ValueError(f"{self.name} constraint can not be applied to"
                             " haploid genomes.")
        if self.lambda_val < 0:
            raise ValueError("Constraint lambda may not be < 0.")
        if self.hparams is None or 'counts_inter_mv' not in self.hparams or (
                self.hparams['counts_inter_mv'] is None):
            raise ValueError(f"{self.name} constraint is missing"
                             f" neccessary hyperparams: 'counts_inter_mv'")

    def _setup(self, counts=None, bias=None):
        if self.lambda_val <= 0:
            return
        if self._var is not None:
            return self._var

        # Beta
        beta = _ambiguate_beta(
            [c.beta for c in counts if c.sum() != 0], counts=counts,
            lengths=self.lengths, ploidy=self.ploidy)

        # Number of fullres beads per lowres bead
        if self.multiscale_factor > 1:
            fullres_per_lowres_bead = _count_fullres_per_lowres_bead(
                multiscale_factor=self.multiscale_factor, lengths=self.lengths,
                ploidy=self.ploidy, fullres_struct_nan=self._fullres_struct_nan)
        else:
            fullres_per_lowres_bead = None

        # Get indices of neighboring beads
        row_nghbr = _neighboring_bead_indices(
            lengths=self.lengths, ploidy=self.ploidy,
            multiscale_factor=self.multiscale_factor)

        # Get bias corresponding to neighboring beads
        row_nghbr_ambig_fullres = _neighboring_bead_indices(
            lengths=self.lengths, ploidy=1, multiscale_factor=1)
        if bias is None or np.all(bias == 1):
            bias_nghbr = 1
        else:
            bias_nghbr = bias.ravel()[row_nghbr_ambig_fullres] * bias.ravel()[
                row_nghbr_ambig_fullres + 1]

        # Get counts corresponding to neighboring beads
        # counts_ambig = ambiguate_counts(
        #     counts=counts, lengths=self.lengths, ploidy=self.ploidy,
        #     exclude_zeros=False)  # FIXME
        if self.multiscale_factor == 1:
            counts_ambig = ambiguate_counts(
                counts=counts, lengths=self.lengths, ploidy=self.ploidy,
                exclude_zeros=False)  # FIXME
            counts_nghbr = counts_ambig[
                row_nghbr_ambig_fullres, row_nghbr_ambig_fullres + 1]
            counts_nghbr[np.isnan(counts_nghbr)] = np.nanmean(counts_nghbr)
            counts_nghbr_mask = None
        else:
            if len(counts) > 2:
                raise NotImplementedError("Make .add and .ambiguate methods for counts object")
            if not (bias is None or np.all(bias == 1)):
                raise NotImplementedError("Need to include zero counts in ambiguated and also get nghbr counts mask")

            counts_ambig = [c for c in counts if c.sum() != 0][0]  # FIXME
            # counts_nghbr = _counts_near_diag(
            #     counts_ambig, self.lengths, ploidy=self.ploidy, nbins=1,
            #     exclude_zeros=True)
            # tmp = _group_counts_multiscale(
            #     counts_nghbr, lengths=self.lengths, ploidy=self.ploidy,
            #     multiscale_factor=self.multiscale_factor)
            # counts_nghbr, indices, indices3d, counts_shape, counts_mask = tmp

            row_nghbr_ambig_lowres = _neighboring_bead_indices(
                lengths=self.lengths, ploidy=1,
                multiscale_factor=self.multiscale_factor)
            mask = (counts_ambig.col == counts_ambig.row + 1) & np.isin(
                counts_ambig.row, row_nghbr_ambig_lowres)
            row_nghbr_counts = counts_ambig.row[mask]

            if not np.array_equal(row_nghbr_counts, row_nghbr_ambig_lowres):
                raise NotImplementedError("double check this code")
                counts_nghbr = np.zeros(row_nghbr_ambig_lowres.shape)
                counts_nghbr[:, row_nghbr_counts] = counts_ambig.data[:, mask]
                tmp = ~np.isin(row_nghbr_ambig_lowres, row_nghbr_counts)
                counts_nghbr[:, tmp] = np.mean(
                    counts_nghbr[:, row_nghbr_counts])
            else:
                counts_nghbr = counts_ambig.data[:, mask]

            counts_nghbr_mask = None  # FIXME

        var = {
            'row_nghbr': row_nghbr, 'counts_nghbr': counts_nghbr,
            'bias_nghbr': bias_nghbr, 'beta': beta,
            'fullres_per_lowres_bead': fullres_per_lowres_bead,
            'counts_nghbr_mask': counts_nghbr_mask}
        if not self._lowmem:
            self._var = var
        return var

    def apply(self, struct, alpha=None, epsilon=None, counts=None, bias=None,
              inferring_alpha=False):
        if self.lambda_val == 0 or (
                inferring_alpha and not self.during_alpha_infer):
            return 0.
        elif alpha is None:
            raise ValueError(f"Must input alpha for {self.name} constraint.")
        var = self._setup(counts=counts, bias=bias)

        counts_inter_mean = self.hparams['counts_inter_mv']['mean']
        lambda_interchrom = counts_inter_mean / 2

        if self.multiscale_factor == 1:
            nghbr_dis = _euclidean_distance(
                struct, row=var['row_nghbr'], col=var['row_nghbr'] + 1)
            bias_nghbr = var['bias_nghbr']
            if not np.all(bias_nghbr == 1):
                bias_nghbr = np.tile(bias_nghbr, self.ploidy)
            lambda_nghbr = (2 * var['beta']) * bias_nghbr * ag_np.power(
                nghbr_dis, alpha)

            # if type(nghbr_dis).__name__ in ('DeviceArray', 'ndarray'):
            #     print(struct.mean())

            lambda_nghbr = lambda_nghbr + lambda_interchrom
            obj = poisson_nll(
                np.tile(var['counts_nghbr'], 2), lambda_pois=lambda_nghbr,
                mean=('bcc_sum' not in self.mods))
        else:
            gamma_mean, gamma_var = get_gamma_moments(
                struct=struct, epsilon=epsilon, alpha=alpha,
                beta=(2 * var['beta']),
                multiscale_factor=self.multiscale_factor,
                row3d=var['row_nghbr'], col3d=var['row_nghbr'] + 1,
                stretch_fullres_beads=self.hparams['stretch_fullres_beads'],
                mean_fullres_nghbr_dis=self.hparams['mean_fullres_nghbr_dis'],
                mods=self.mods)

            # Add lambda_interchrom (increases gamma mean & Poisson variance)
            # FIXME TODO we want fullres lambda_interchrom, right?
            gamma_mean = gamma_mean + (
                lambda_interchrom / np.square(self.multiscale_factor))  # TODO this is the best option, right?

            theta = gamma_var / gamma_mean
            k = ag_np.square(gamma_mean) / gamma_var

            data_per_bin = (
                var['fullres_per_lowres_bead'][var['row_nghbr']]) * (
                var['fullres_per_lowres_bead'][var['row_nghbr'] + 1])

            obj = gamma_poisson_nll(
                theta=theta, k=k, data=np.tile(var['counts_nghbr'], 2),
                bias_per_bin=var['bias_nghbr'], mask=var['counts_nghbr_mask'],
                # data_per_bin=data_per_bin,  # FIXME adding this makes the obj wrong?
                mean=('bcc_sum' not in self.mods),
                mods=self.mods)

            lambda_nghbr = gamma_mean  # TODO temp

        if False and 'debug' in self.mods and type(obj).__name__ in ('DeviceArray', 'ndarray'):
            to_print = f"ùîº[c]={var['counts_nghbr'].mean():.3g}\t   ŒºNB={lambda_nghbr.mean():.2g}"
            if epsilon is not None:
                to_print += f"\t   V[c]={var['counts_nghbr'].var(axis=0).mean():.3g}"
                to_print += f"\t   œÉ¬≤NB={(gamma_mean + gamma_var).mean():.3g}\t   Œµ={ag_np.asarray(epsilon).mean():.2g}"
                # lambda_nghbr = (2 * var['beta']) * var['bias_nghbr'] * ag_np.power(
                #     nghbr_dis, alpha) + lambda_interchrom
                # to_print += f"\t   Œº*={lambda_nghbr.mean():.2g}"
            print(to_print + f"\t   obj={obj:.3g}", flush=True)
            # exit(1)

        if not ag_np.isfinite(obj):
            raise ValueError(f"{self.name} constraint is {obj}.")
        return self.lambda_val * obj


class HomologSeparating2022(Constraint):
    """TODO"""

    def __init__(self, lambda_val, lengths, ploidy, multiscale_factor=1,
                 hparams=None, fullres_struct_nan=None, lowmem=False, mods=[]):
        self.abbrev = "hsc"
        self.name = "Homolog separating (2022)"
        self.during_alpha_infer = True
        self.lambda_val = lambda_val
        self.lengths = np.asarray(lengths)
        self.lengths_lowres = decrease_lengths_res(
            self.lengths, multiscale_factor=multiscale_factor)
        self.ploidy = ploidy
        self.multiscale_factor = multiscale_factor
        self.hparams = hparams
        self._fullres_struct_nan = fullres_struct_nan  # For self._setup() only
        self._lowmem = lowmem
        self._var = None
        self.mods = mods  # TODO remove

        self.check()

    def check(self):
        if self.ploidy == 1 and self.lambda_val > 0:
            raise ValueError(f"{self.name} constraint can not be applied to"
                             " haploid genomes.")
        if self.lambda_val < 0:
            raise ValueError("Constraint lambda may not be < 0.")
        # Hyperparam: perc_diff  # TODO maybe remove
        if self.hparams is None:
            self.hparams = {'perc_diff': None}
        if 'perc_diff' not in self.hparams:
            self.hparams['perc_diff'] = None
        if self.hparams['perc_diff'] is not None and (
                self.hparams['perc_diff'] < 0 or self.hparams['perc_diff'] > 1):
            raise ValueError("'perc_diff' must be between 0 and 1.")
        # Hyperparam: counts_inter_mv
        if self.hparams is None or 'counts_inter_mv' not in self.hparams or (
                self.hparams['counts_inter_mv'] is None):
            raise ValueError(f"{self.name} constraint is missing"
                             f" neccessary hyperparams: 'counts_inter_mv'")

    def _setup(self, counts=None, bias=None):
        if self.lambda_val <= 0:
            return
        if self._var is not None:
            return self._var

        beta = _ambiguate_beta(
            [c.beta for c in counts if c.sum() != 0], counts=counts,
            lengths=self.lengths, ploidy=self.ploidy)

        if self.multiscale_factor > 1:
            fullres_per_lowres_bead = _count_fullres_per_lowres_bead(
                multiscale_factor=self.multiscale_factor, lengths=self.lengths,
                ploidy=self.ploidy, fullres_struct_nan=self._fullres_struct_nan)
        else:
            fullres_per_lowres_bead = None

        if (self.lengths_lowres.size > 1 and (
                'interhmlg_intrachrom' in self.mods or 'intrah_interc' in self.mods)):
            n = self.lengths_lowres.sum()
            mask_intrachrom = _intra_mask(
                (n, n), lengths_at_res=self.lengths_lowres)
        else:
            mask_intrachrom = None

        var = {'beta': beta, 'fullres_per_lowres_bead': fullres_per_lowres_bead,
               'mask_intrachrom': mask_intrachrom}
        if not self._lowmem:
            self._var = var
            self._fullres_struct_nan = None  # No longer needed unless lowmem
        return var

    def apply(self, struct, alpha=None, epsilon=None, counts=None, bias=None,
              inferring_alpha=False):
        if self.lambda_val == 0 or (
                inferring_alpha and not self.during_alpha_infer):
            return 0.
        elif alpha is None:
            raise ValueError(f"Must input alpha for {self.name} constraint.")
        var = self._setup(counts=counts, bias=bias)

        # Get inter-homolog distances
        n = self.lengths_lowres.sum()
        row, col = (x.ravel() for x in np.indices((n, n)))
        if 'same_locus' in self.mods:
            mask = row == col
            row = row[mask]
            col = col[mask]
        elif ('interhmlg_intrachrom' in self.mods and 'mean' not in self.mods and 'per_chrom' not in self.mods):
            row = row[var['mask_intrachrom']]
            col = col[var['mask_intrachrom']]
        if 'sum2' in self.mods:
            mask = row > col
            row = row[mask]
            col = col[mask]
            row2 = np.append(row, col)
            col2 = np.append(col, row)
            row = row2
            col = col2
        dis_interhmlg = _euclidean_distance(struct, row=row, col=col + n)
        row_final = row
        col_final = col + n

        if 'intrah_interc' in self.mods:
            mask_intraH = np.invert(var['mask_intrachrom']) & (col > row)
            row_intraH = row[mask_intraH]
            col_intraH = col[mask_intraH]
            dis_intraH = _euclidean_distance(
                struct, row=np.append(row_intraH, row_intraH + n),
                col=np.append(col_intraH, col_intraH + n))
            row_final = np.concatenate([row_final, row_intraH, row_intraH + n])
            col_final = np.concatenate([col_final, col_intraH, col_intraH + n])
            if 'per_chrom' not in self.mods:
                dis_interhmlg = ag_np.append(dis_interhmlg, dis_intraH)
            else:
                raise NotImplementedError

        counts_inter_mv = self.hparams['counts_inter_mv']
        if 'div4' in self.mods:
            div_by = var['beta']
        else:
            div_by = 4 * var['beta']

        if 'mse' in self.mods:
            # Get lambda_interhmlg
            if 'use_gmean' in self.mods and self.multiscale_factor > 1:
                lambda_interhmlg = get_gamma_moments(
                    struct=struct, epsilon=epsilon, alpha=alpha,
                    beta=4 * var['beta'], multiscale_factor=self.multiscale_factor,
                    row3d=row, col3d=col + n, mods=self.mods, return_var=False,
                    stretch_fullres_beads=self.hparams['stretch_fullres_beads'],
                    mean_fullres_nghbr_dis=self.hparams['mean_fullres_nghbr_dis'])  # FIXME
            else:
                dis_alpha_interhmlg = ag_np.power(dis_interhmlg, alpha)
                lambda_interhmlg = (4 * var['beta']) * dis_alpha_interhmlg

            # Get mean inter-chrom counts
            counts_inter_mean = counts_inter_mv['mean']
            k = counts_inter_mv['est_gamma_k']
            theta = counts_inter_mv['est_gamma_theta']
            if 'hsc_inv' in self.mods:
                counts_inter_mean, var = gamma_to_invgamma_to_gamma(
                    k=k, theta=theta, scale=(1 / div_by), return_moments=True)
                lambda_interhmlg = ag_np.power(dis_interhmlg, -alpha)
            elif 'hsc_gen' in self.mods:
                counts_inter_mean, var = gamma_to_gengamma_to_gamma(
                    k=k, theta=theta, q=ag_np.abs(1 / alpha),
                    scale=(1 / div_by), return_moments=True)
                lambda_interhmlg = ag_np.power(dis_interhmlg, -1)
            elif 'hsc_invgen' in self.mods:
                k, theta = gamma_to_gengamma_to_gamma(
                    k=k, theta=theta, q=ag_np.abs(1 / alpha),
                    scale=(1 / div_by), verbose=False)
                counts_inter_mean, var = gamma_to_invgamma_to_gamma(
                    k=k, theta=theta, scale=1, return_moments=True)
                lambda_interhmlg = dis_interhmlg

            # Get mean per pair of chromosomes
            if 'mean' in self.mods:
                lambda_interhmlg = lambda_interhmlg.reshape(n, n)
                nchrom = self.lengths.size
                interhmlg_mean = ag_np.zeros((nchrom, nchrom))
                begin_i = end_i = 0
                for i in range(nchrom):
                    end_i = end_i + ag_np.int32(self.lengths_lowres[i])
                    begin_j = end_j = 0
                    for j in range(nchrom):
                        end_j = end_j + ag_np.int32(self.lengths_lowres[j])
                        if 'interhmlg_intrachrom' in self.mods and i != j:
                            begin_j = end_j
                            continue
                        # tmp = ag_np.mean(
                        #     lambda_interhmlg[begin_i:end_i, begin_j:end_j])
                        # print(f"i={i}=[{begin_i}:{end_i}],  j={j}=[{begin_j}:{end_j}],   {tmp}")
                        interhmlg_mean = interhmlg_mean.at[i, j].set(ag_np.mean(
                            lambda_interhmlg[begin_i:end_i, begin_j:end_j]))
                        begin_j = end_j
                    begin_i = end_i
                lambda_interhmlg = interhmlg_mean
                if 'interhmlg_intrachrom' in self.mods:
                    lambda_interhmlg = lambda_interhmlg[lambda_interhmlg != 0]

            # Optionally only apply obj if |actual-expected| > window
            if 'flex' in self.mods:
                obj = _mse_flexible(
                    actual=lambda_interhmlg, expected=counts_inter_mean,
                    cutoff=self.hparams['perc_diff'], scale_by_expected=True)
            else:
                obj = _mse_outside_of_window(
                    actual=lambda_interhmlg, expected=counts_inter_mean,
                    cutoff=self.hparams['perc_diff'], scale_by_expected=True)

            if 'debug' in self.mods and type(obj).__name__ in ('DeviceArray', 'ndarray'):
                tmp = f'œÉ¬≤={lambda_interhmlg.var():.2g}'
                if 'mean' in self.mods:
                    tmp = tmp + '\t   Œª=[' + ' '.join([f"{x:.2g}" for x in lambda_interhmlg._value.ravel().tolist()]) + ']'
                to_print = f"c={counts_inter_mean:.2g}\t   ¬µ={lambda_interhmlg.mean():.2g}\t   {tmp}"
                to_print += f"\t   OBJ={obj:.2g}"
                if epsilon is not None:
                    to_print += f"\t   Œµ={epsilon:.2g}"
                print(to_print, flush=True)


        elif ('hsc_gamma' in self.mods) or ('hsc_invgamma' in self.mods) or ('hsc_gengamma' in self.mods) or ('hsc_normal' in self.mods) or ('hsc_invgengamma' in self.mods):
            # NOTE: DON'T MULTIPLY lambda_interhmlg BY square(multiscale_factor)... and use highres counts_inter mean & var for all
            if 'div4' in self.mods or 'try1' in self.mods:
                lambda_interhmlg = var['beta'] * ag_np.power(dis_interhmlg, alpha)
            else:
                lambda_interhmlg = (4 * var['beta']) * ag_np.power(dis_interhmlg, alpha)

            mean = counts_inter_mv['est_gamma_mean']
            variance = counts_inter_mv['est_gamma_var']

            # variance = lambda_interhmlg.variance()
            # variance = relu_max(variance, counts_inter_mv['gamma_var_min'])
            # variance = relu_min(variance, counts_inter_mv['gamma_var_max'])
            # theta = variance / mean
            # k = mean / est_gamma_theta

            if 'flex_var' in self.mods:
                variance_max = counts_inter_mv['var']
                variance = relu_min(lambda_interhmlg.var(), variance_max)
                k = ag_np.square(mean) / variance
                theta = variance / mean
            elif 'flex_var2' in self.mods:
                variance_max = counts_inter_mv['est_gamma_var']
                variance = relu_min(lambda_interhmlg.var(), variance_max)
                k = ag_np.square(mean) / variance
                theta = variance / mean

                # mad = ag_np.median(ag_np.absolute(
                #     nghbr_dis - ag_np.median(nghbr_dis)))
                # sigma_tmp = 1.4826 * mad
            else:
                k = counts_inter_mv['est_gamma_k']
                theta = counts_inter_mv['est_gamma_theta']

            if 'hsc_invgamma' in self.mods:
                k, theta = gamma_to_invgamma_to_gamma(
                    k=k, theta=theta, scale=(1 / div_by), verbose=False)
                obj = -logpdf_gamma(
                    ag_np.power(dis_interhmlg, -alpha), a=k, scale=theta).mean()
            elif 'hsc_gengamma' in self.mods:
                k, theta = gamma_to_gengamma_to_gamma(
                    k=k, theta=theta, q=ag_np.abs(1 / alpha),
                    scale=(1 / div_by), verbose=False)
                obj = -logpdf_gamma(
                    ag_np.power(dis_interhmlg, -1), a=k, scale=theta).mean()
            elif 'hsc_invgengamma' in self.mods:
                k, theta = gamma_to_gengamma_to_gamma(
                    k=k, theta=theta, q=ag_np.abs(1 / alpha),
                    scale=(1 / div_by), verbose=False)
                k, theta = gamma_to_invgamma_to_gamma(
                    k=k, theta=theta, scale=1, verbose=False)
                obj = -logpdf_gamma(
                    dis_interhmlg, a=k, scale=theta).mean()

            elif 'hsc_normal' in self.mods:
                obj = -logpdf_norm(
                    lambda_interhmlg, loc=mean, scale=np.sqrt(variance)).mean()
            elif 'hsc_gamma' in self.mods:
                obj = -logpdf_gamma(lambda_interhmlg, a=k, scale=theta).mean()


            # FIXME FIXME2
            if 'debug' in self.mods and type(obj).__name__ in ('DeviceArray', 'ndarray'):
                to_print = f"ùîº[c]={mean:.2g}\t   Œº={lambda_interhmlg.mean():.2g}\t   var={variance:.2g}\t   œÉ¬≤={lambda_interhmlg.var():.2g}"

                if 'hsc_invgamma' in self.mods:
                    mean2 = k * theta
                    var2 = k * (theta ** 2)
                    lam2 = ag_np.power(dis_interhmlg, -alpha)
                    to_print += f"\t   ... ùîº[c]={mean2:.2g}\t   Œº={lam2.mean():.2g}\t   var={var2:.2g}\t   œÉ¬≤={lam2.var():.2g}"
                if 'hsc_gengamma' in self.mods:
                    mean2 = k * theta
                    var2 = k * (theta ** 2)
                    lam2 = ag_np.power(dis_interhmlg, -1)
                    to_print += f"\t   ... ùîº[c]={mean2:.2g}\t   Œº={lam2.mean():.2g}\t   var={var2:.2g}\t   œÉ¬≤={lam2.var():.2g} ..."
                if 'hsc_invgengamma' in self.mods:
                    mean2 = k * theta
                    var2 = k * (theta ** 2)
                    lam2 = dis_interhmlg
                    to_print += f"\t   ... ùîº[c]={mean2:.2g}\t   Œº={lam2.mean():.2g}\t   var={var2:.2g}\t   œÉ¬≤={lam2.var():.2g} ..."

                # k = ag_np.square(lambda_interhmlg.mean()) / lambda_interhmlg.var()
                # theta = lambda_interhmlg.var() / lambda_interhmlg.mean()
                # to_print += f"\t   k*={counts_inter_mv['est_gamma_k']:.2g}\t   k={k:.2g}\t   Œ∏*={counts_inter_mv['est_gamma_theta']:.2g}\t   Œ∏={theta:.2g}"

                to_print += f"\t   OBJ={obj:.2g}"
                if epsilon is not None:
                    to_print += f"\t   Œµ={epsilon:.2g}"
                print(to_print, flush=True)
                # exit(1)
        elif 'nb3' in self.mods:
            if 'div4' in self.mods or 'try1' in self.mods:
                lambda_interhmlg = var['beta'] * ag_np.power(dis_interhmlg, alpha)
            else:
                lambda_interhmlg = (4 * var['beta']) * ag_np.power(dis_interhmlg, alpha)

            counts_inter = counts_inter_mv['vals'].reshape(-1, 1)

            lambda_mean = lambda_interhmlg.mean()
            lambda_var = lambda_interhmlg.var()
            k = ag_np.square(lambda_mean) / lambda_var
            theta = lambda_var / lambda_mean
            obj = gamma_poisson_nll(
                theta=theta, k=k, data=counts_inter, bias_per_bin=None, mods=self.mods)  # FIXME need to add bias and input non-normed counts??

            if 'debug' in self.mods and type(obj).__name__ in ('DeviceArray', 'ndarray'):
                to_print = f"NB3: c={counts_inter_mv['mean']:.2g}\t   Œº={lambda_mean:.2g}\t   œÉ¬≤={lambda_var:.2g}\t   OBJ={obj:.2g}"
                if epsilon is not None:
                    to_print += f"\t   Œµ={ag_np.asarray(epsilon).mean():.2g}"
                print(to_print, flush=True)
        elif ('kl_nb' in self.mods) or ('js_nb' in self.mods):
            # Get lambda_interhmlg
            if 'use_gmean' in self.mods and self.multiscale_factor > 1:
                lambda_interhmlg, lambda_interhmlg_var = get_gamma_moments(
                    struct=struct, epsilon=epsilon, alpha=alpha,
                    beta=4 * var['beta'], multiscale_factor=self.multiscale_factor,
                    row3d=row_final, col3d=col_final, mods=self.mods, return_var=True,
                    stretch_fullres_beads=self.hparams['stretch_fullres_beads'],
                    mean_fullres_nghbr_dis=self.hparams['mean_fullres_nghbr_dis'])  # FIXME
                if 'add_gvar' in self.mods:
                    lambda_interhmlg_var = lambda_interhmlg_var.mean()
                else:
                    lambda_interhmlg_var = 0
            else:
                lambda_interhmlg = (4 * var['beta']) * ag_np.power(dis_interhmlg, alpha)
                lambda_interhmlg_var = 0
            if 'sum2' in self.mods:
                lambda_interhmlg = lambda_interhmlg / 2
                half = int(lambda_interhmlg.size / 2)
                lambda_interhmlg = lambda_interhmlg[:half] + lambda_interhmlg[half:]

            # if 'lowres4lowres' in self.mods and self.multiscale_factor > 1:
            #     counts_inter_mv = counts_inter_mv[self.multiscale_factor]
            #     lambda_interhmlg = lambda_interhmlg * np.square(self.multiscale_factor)

            counts_inter_pmf = counts_inter_mv['nb_pmf']

            if 'per_chrom' in self.mods:
                bins = self.lengths_lowres.cumsum()
                row_binned = np.digitize(row, bins)
                col_binned = np.digitize(col, bins)

                obj = 0
                nchrom = self.lengths.size
                for i in range(nchrom):
                    for j in range(nchrom):
                        mask = (row_binned == i) & (col_binned == j)
                        obj = obj + negbinom_divergence(
                            gamma_mean=lambda_interhmlg[mask].mean(),
                            gamma_var=lambda_interhmlg[mask].var() + lambda_interhmlg_var,
                            pmf_x=counts_inter_pmf['x'],
                            pmf_y=counts_inter_pmf['y'], mods=self.mods)
                obj = obj / np.square(nchrom)
            elif 'per_section' in self.mods:
                obj = 0
                divide_obj_by = 2

                if 'intrah_interc' in self.mods:
                    lambda_intraH = lambda_interhmlg[-dis_intraH.size:]
                    lambda_interhmlg = lambda_interhmlg[:-dis_intraH.size]

                    half = int(lambda_intraH.size / 2)
                    obj = obj + negbinom_divergence(
                        gamma_mean=lambda_intraH[:half].mean(),
                        gamma_var=lambda_intraH[:half].var() + lambda_interhmlg_var,
                        pmf_x=counts_inter_pmf['x'],
                        pmf_y=counts_inter_pmf['y'], mods=self.mods)
                    obj = obj + negbinom_divergence(
                        gamma_mean=lambda_intraH[half:].mean(),
                        gamma_var=lambda_intraH[half:].var() + lambda_interhmlg_var,
                        pmf_x=counts_inter_pmf['x'],
                        pmf_y=counts_inter_pmf['y'], mods=self.mods)
                    divide_obj_by += 2

                half = int(lambda_interhmlg.size / 2)
                obj = obj + negbinom_divergence(
                    gamma_mean=lambda_interhmlg[:half].mean(),
                    gamma_var=lambda_interhmlg[:half].var() + lambda_interhmlg_var,
                    pmf_x=counts_inter_pmf['x'],
                    pmf_y=counts_inter_pmf['y'], mods=self.mods)
                obj = obj + negbinom_divergence(
                    gamma_mean=lambda_interhmlg[half:].mean(),
                    gamma_var=lambda_interhmlg[half:].var() + lambda_interhmlg_var,
                    pmf_x=counts_inter_pmf['x'],
                    pmf_y=counts_inter_pmf['y'], mods=self.mods)
                obj = obj / divide_obj_by
            elif 'per_half' in self.mods:
                obj = 0
                divide_obj_by = 1

                if 'intrah_interc' in self.mods:
                    lambda_intraH = lambda_interhmlg[-dis_intraH.size:]
                    lambda_interhmlg = lambda_interhmlg[:-dis_intraH.size]
                    obj = obj + negbinom_divergence(
                        gamma_mean=lambda_intraH.mean(),
                        gamma_var=lambda_intraH.var() + lambda_interhmlg_var,
                        pmf_x=counts_inter_pmf['x'],
                        pmf_y=counts_inter_pmf['y'], mods=self.mods)
                    divide_obj_by += 1

                obj = obj + negbinom_divergence(
                    gamma_mean=lambda_interhmlg.mean(),
                    gamma_var=lambda_interhmlg.var() + lambda_interhmlg_var,
                    pmf_x=counts_inter_pmf['x'],
                    pmf_y=counts_inter_pmf['y'], mods=self.mods)
                obj = obj / divide_obj_by

            else:
                obj = negbinom_divergence(
                    gamma_mean=lambda_interhmlg.mean(),
                    gamma_var=lambda_interhmlg.var() + lambda_interhmlg_var,
                    pmf_x=counts_inter_pmf['x'], pmf_y=counts_inter_pmf['y'],
                    mods=self.mods)

            if 'debug' in self.mods and type(obj).__name__ in ('DeviceArray', 'ndarray'):
                gamma_mean = lambda_interhmlg.mean()
                gamma_var = lambda_interhmlg.var() + lambda_interhmlg_var
                to_print = f"KL_NB: ùîº[c]={counts_inter_mv['mean']:.2g}\t   Œº={gamma_mean:.2g}\t   œÉ¬≤={gamma_var:.2g}\t   Var[c]={counts_inter_mv['var']:.2g}\t   NBœÉ¬≤={gamma_mean + gamma_var:.2g}\t   OBJ={obj:.2g}"
                # print(dis_interhmlg.size, lambda_interhmlg.size, lambda_intraH.size)
                # from scipy.special import rel_entr
                # kl_test = rel_entr(counts_inter_pmf['y'], lambda_pmf if isinstance(lambda_pmf, np.ndarray) else lambda_pmf._value).sum()
                # to_print += f"\t   TEST={kl_test:.3g}"
                if epsilon is not None:
                    to_print += f"\t   Œµ={ag_np.asarray(epsilon).mean():.2g}"
                print(to_print, flush=True)
        elif False:

            dis_intraH_interC = _euclidean_distance(
                struct, row=np.append(row, row + n), col=np.append(col, col + n))



        else:
            counts_inter_mean = counts_inter_mv['mean']

            dis_alpha_interhmlg = ag_np.power(dis_interhmlg, alpha)
            lambda_interhmlg = (4 * var['beta']) * dis_alpha_interhmlg
            # lambda_interhmlg = lambda_interhmlg * np.square(self.multiscale_factor)  # TODO this is the best option, right?
            obj = poisson_nll(counts_inter_mean, lambda_pois=lambda_interhmlg)

            if 'debug' in self.mods and type(obj).__name__ in ('DeviceArray', 'ndarray'):
                to_print = f"c={counts_inter_mean:.2g}\t   Œº={lambda_interhmlg.mean():.2g}\t   obj={obj:.2g}"
                if epsilon is not None:
                    to_print += f"\t   Œµ={epsilon:.2g}"
                print(to_print, flush=True)

        if not ag_np.isfinite(obj):
            raise ValueError(f"{self.name} constraint is {obj}.")
        return self.lambda_val * obj


def negbinom_divergence(gamma_mean, gamma_var, pmf_x, pmf_y, mods=[]):
    gamma_theta = gamma_var / gamma_mean
    n = gamma_k = ag_np.square(gamma_mean) / gamma_var
    p = 1 / (gamma_theta + 1)

    lambda_pmf = ag_np.exp(logpmf_negbinom(pmf_x, n=n, p=p))

    if 'js_nb' in mods:
        kl = kl_divergence(p=pmf_y, q=lambda_pmf)
        divergence = js_divergence(p=pmf_y, q=lambda_pmf)
        if 'debug2' in mods and type(divergence).__name__ in ('DeviceArray', 'ndarray'):
            print(f"{pmf_x.size}\tKL={kl:.3g}\tJS={divergence:.3g}\t\tKL/n={kl/pmf_x.size:.3g}\tJS/n={divergence/pmf_x.size:.3g}")
    else:
        divergence = kl_divergence(p=pmf_y, q=lambda_pmf)
        if 'debug2' in mods and type(divergence).__name__ in ('DeviceArray', 'ndarray'):
            print(f"{pmf_x.size}\t{pmf_y.mean():.3g}\tKL={divergence:.3g}\t\tKL/n={divergence/pmf_x.size:.3g}")

    return divergence


def kl_divergence(p, q):
    mask = (p != 0)
    if mask.sum() == mask.size:
        tmp = p * ag_np.log(p / q)
    else:
        tmp = p[mask] * ag_np.log(p[mask] / q[mask])
    return ag_np.sum(tmp)


def js_divergence(p, q):
    m = (p + q) / 2
    return (kl_divergence(p, m) + kl_divergence(q, m)) / 2


def _mse_flexible(actual, expected, cutoff=None, scale_by_expected=True):
    """TODO"""

    if scale_by_expected:
        actual = actual / expected
        expected = 1

    if cutoff is not None and cutoff != 0:
        if scale_by_expected:
            window = cutoff
        else:
            window = cutoff * expected

        mle_expected = ag_np.mean(actual)

        # print(f"{window=:g}")
        # print(f"{expected=:g}")
        # print(f"{mle_expected=:g}")

        sub_from_expected = relu_min(relu(expected - mle_expected), window)
        add_to_expected = relu_min(relu(mle_expected - expected), window)
        expected = expected + add_to_expected - sub_from_expected

        # print(f"{add_to_expected=:g}")
        # print(f"{sub_from_expected=:g}")
        # print(f"{expected=:g}")

    diff = expected - actual
    mse = ag_np.mean(ag_np.square(diff))

    return mse


def _mse_outside_of_window(actual, expected, cutoff=None, scale_by_expected=True, new=True):
    """TODO"""
    if scale_by_expected:
        diff = 1 - actual / expected
    else:
        diff = expected - actual

    if cutoff is None:
        diff = relu(diff)
        mse = ag_np.mean(ag_np.square(diff))
        raise ValueError("I thought we weren't doing ReLU for HSC anymore")  # TODO remove ValueError
        return mse

    if cutoff == 0:
        mse = ag_np.mean(ag_np.square(diff))
        return mse

    if scale_by_expected:
        window = cutoff
    else:
        window = cutoff * expected

    if new:
        n = diff.size
        diff_gt0 = relu(diff)
        diff_lt0 = -relu(-diff)
        diff_gt0 = relu(diff_gt0 - window)
        diff_lt0 = -relu(-(diff_lt0 + window))
        mse = (ag_np.square(diff_gt0).sum() + ag_np.square(diff_lt0).sum()) / n
    else:  # TODO remove old code
        window = ag_np.array(window)
        if window.size == 1 and actual.size > 1:
            window = ag_np.tile(window, actual.size)
        gt0 = diff > 0
        diff = diff.at[gt0].set(relu(diff[gt0] - window[gt0]))
        diff = diff.at[~gt0].set(-relu(-(diff[~gt0] + window[~gt0])))
        mse = ag_np.mean(ag_np.square(diff))

    return mse


def prep_constraints(counts, lengths, ploidy, multiscale_factor=1,
                     bcc_lambda=0, hsc_lambda=0, bcc_version='2019',
                     hsc_version='2019', counts_inter_mv=None,
                     est_hmlg_sep=None, hsc_perc_diff=None,
                     fullres_struct_nan=None, stretch_fullres_beads=None,
                     mean_fullres_nghbr_dis=None, verbose=True, mods=[]):
    """TODO"""

    # TODO remove
    if mods is None:
        mods = []
    elif isinstance(mods, str):
        mods = mods.lower().split('.')
    else:
        mods = [x.lower() for x in mods]

    if bcc_version is None:
        bcc_version = '2019'
    bcc_version = str(bcc_version)
    if hsc_version is None:
        hsc_version = '2019'
    hsc_version = str(hsc_version)

    bcc_class = {
        '2019': BeadChainConnectivity2019, '2021': BeadChainConnectivity2021,
        '2022': BeadChainConnectivity2022}
    hsc_class = {
        '2019': HomologSeparating2019, '2022': HomologSeparating2022}
    bcc_hparams = {
        '2019': None, '2021': None,
        '2022': {'counts_inter_mv': counts_inter_mv,
                 'stretch_fullres_beads': stretch_fullres_beads,
                 'mean_fullres_nghbr_dis': mean_fullres_nghbr_dis}}
    hsc_hparams = {
        '2019': {'est_hmlg_sep': est_hmlg_sep, 'perc_diff': hsc_perc_diff},
        '2022': {'counts_inter_mv': counts_inter_mv,
                 'perc_diff': hsc_perc_diff,
                 'stretch_fullres_beads': stretch_fullres_beads,
                 'mean_fullres_nghbr_dis': mean_fullres_nghbr_dis}}

    constraints = []
    if bcc_lambda != 0:
        constraints.append(bcc_class[bcc_version](
            bcc_lambda, lengths=lengths, ploidy=ploidy,
            multiscale_factor=multiscale_factor,
            hparams=bcc_hparams[bcc_version],
            fullres_struct_nan=fullres_struct_nan, lowmem=False, mods=mods))
    if hsc_lambda != 0:
        constraints.append(hsc_class[hsc_version](
            hsc_lambda, lengths=lengths, ploidy=ploidy,
            multiscale_factor=multiscale_factor,
            hparams=hsc_hparams[hsc_version],
            fullres_struct_nan=fullres_struct_nan, lowmem=False, mods=mods))

    # TODO have var=None input to Constraint._setup = share var dict for all (only add to var if not already found)
    # TODO if NOT lowmem, run Constraint._setup method here = share var dict for all

    # TODO have var=None input to Constraint.apply = share var dict for all during opt if lowmem
    # TODO if lowmem, run Constraint._setup before .apply during opt = share var dict for all during opt if lowmem

    return constraints


def get_fullres_counts_interchrom(counts, lengths, ploidy, verbose=False):
    """TODO"""  # TODO remove function?

    if lengths.size == 1:
        raise ValueError(
            "Must input counts_interchrom if inferring single chromosome.")
    counts_ambig = ambiguate_counts(
        counts=counts, lengths=lengths, ploidy=ploidy, exclude_zeros=False)
    counts_interchrom = _inter_counts(
        counts_ambig, lengths, ploidy=ploidy, exclude_zeros=False)
    counts_interchrom = counts_interchrom[~np.isnan(counts_interchrom)]
    if verbose:
        print(f"Inter-chromosomal counts Œº={counts_interchrom.mean():.3g}"
              f"  œÉ¬≤={counts_interchrom.var():.3g}", flush=True)
    return counts_interchrom


def get_counts_interchrom(counts, lengths, ploidy, multiscale_factor=1,
                          fullres_struct_nan=None, verbose=False):
    """TODO"""

    if lengths.size == 1:
        raise ValueError(
            "Must input counts_interchrom if inferring single chromosome.")
    lengths_lowres = decrease_lengths_res(
        lengths, multiscale_factor=multiscale_factor)

    counts_ambig = ambiguate_counts(
        counts=counts, lengths=lengths_lowres, ploidy=ploidy,
        exclude_zeros=False)
    counts_interchrom = _inter_counts(
        counts_ambig, lengths_at_res=lengths_lowres, ploidy=ploidy,
        exclude_zeros=False)
    if multiscale_factor > 1:
        fullres_per_lowres_bead = _count_fullres_per_lowres_bead(
            multiscale_factor=multiscale_factor, lengths=lengths,
            ploidy=1, fullres_struct_nan=fullres_struct_nan)
        mask = fullres_per_lowres_bead == multiscale_factor
        counts_interchrom[~mask, :] = np.nan
        counts_interchrom[:, ~mask] = np.nan

    counts_interchrom = counts_interchrom[~np.isnan(counts_interchrom)]
    if verbose:
        print(f"Inter-chromosomal counts Œº={counts_interchrom.mean():.3g}"
              f"  œÉ¬≤={counts_interchrom.var():.3g}", flush=True)
    return counts_interchrom


def gamma_to_gengamma_to_gamma(k, theta, q, scale=1, return_moments=False, verbose=False):
    # Scale original gamma distribution
    theta = theta * scale
    # Get GenGamma params
    p = 1 / q
    d = k / q
    a = ag_np.power(theta, q)
    # Get GenGamma moments
    mean = a * ag_np.exp(gammaln((d + 1) / p) - gammaln(d / p))
    var = ag_np.square(a) * ag_np.exp(
        gammaln((d + 2) / p) - gammaln(d / p)) - ag_np.square(mean)
    if verbose:
        print(f"OLD: Œº={k * theta:.2g}\t    œÉ¬≤={k * (theta ** 2):.2g}", flush=True)
        print(f"NEW: Œº={mean:.2g}\t    œÉ¬≤={var:.2g}", flush=True)
    if return_moments:
        return mean, var
    # Get params of new gamma distribution
    theta_new = var / mean
    k_new = (mean ** 2) / var
    return k_new, theta_new


def gamma_to_invgamma_to_gamma(k, theta, scale=1, return_moments=False, verbose=False):  # FIXME FIXME2
    # Scale original gamma distribution
    theta = theta * scale
    # Get InvGamma params
    a = k
    b = 1 / theta
    # Get InvGamma moments
    mean = b / (a - 1)
    var = (mean ** 2) / (a - 2)
    if verbose:
        print(f"OLD: Œº={k * theta:.2g}\t    œÉ¬≤={k * (theta ** 2):.2g}", flush=True)
        print(f"NEW: Œº={mean:.2g}\t    œÉ¬≤={var:.2g}", flush=True)
    if return_moments:
        return mean, var
    # Get params of new gamma distribution
    theta_new = var / mean
    k_new = (mean ** 2) / var
    return k_new, theta_new


def calc_counts_interchrom(counts, lengths, ploidy, filter_threshold=0.04,
                           normalize=True, bias=None, verbose=True, mods=[]):
    """TODO"""

    counts, bias, lengths, _, _, _, _ = load_data(
        counts=counts, lengths_full=lengths, ploidy=ploidy,
        filter_threshold=filter_threshold, normalize=normalize, bias=bias,
        exclude_zeros=False, verbose=False)
    if lengths.size == 1:
        raise ValueError(
            "Must input counts_interchrom if inferring a single chromosome.")
    if bias is not None and bias.size != lengths.sum() * ploidy:
        raise ValueError("Length of bias vector does not match the counts")

    # Get normalized inter-chromosomal counts
    counts_ambig = ambiguate_counts(
        counts=counts, lengths=lengths, ploidy=ploidy, exclude_zeros=False)
    counts_interchrom = _inter_counts(
        counts_ambig, lengths, ploidy=ploidy, exclude_zeros=False)
    if bias is not None:
        counts_ambig /= bias.reshape(1, -1)
        counts_ambig /= bias.reshape(-1, 1)

    # Get mean & var of full-res normalized inter-chromosomal counts
    counts_inter_mv = {}
    tmp = counts_interchrom[~np.isnan(counts_interchrom)]
    if 'try1' in mods:
        tmp = tmp / 4
    counts_inter_mv = {'mean': tmp.mean(), 'var': tmp.var()}

    if 'nb3' in mods:
        counts_inter_mv['vals'] = tmp

    if 'kl_nb' in mods and bias is not None:
        raise ValueError("bias for kl_nb")
    nb_pmf_x = np.arange(tmp.max() + 1, dtype=int)
    bincount_y = np.bincount(tmp.astype(int))
    nb_pmf_y = bincount_y / tmp.size

    if ('js_nb' not in mods):
        mask = nb_pmf_y != 0
        nb_pmf_x = nb_pmf_x[mask]
        nb_pmf_y = nb_pmf_y[mask]
    if '1p' in mods:
        cutoff = 0.01
        print([float(f'{x:.3g}') for x in nb_pmf_y])
        print((nb_pmf_y > cutoff).sum(), nb_pmf_y.size); print()
        mask = nb_pmf_y > cutoff
        nb_pmf_x = nb_pmf_x[mask]
        nb_pmf_y = nb_pmf_y[mask]

    counts_inter_mv['nb_pmf'] = {'x': nb_pmf_x, 'y': nb_pmf_y}


    # # Get mean of (c_ij / beta) ^ (-1/alpha)
    # beta_ambig = _ambiguate_beta(
    #     beta, counts=counts, lengths=lengths, ploidy=ploidy)
    # tmp2 = np.power(tmp / beta_ambig, np.abs(1 / alpha))
    # counts_inter_mv['inv_dis_mean'] = tmp2.mean()
    # print('**********', tmp2.mean())

    # Get estimated gamma theta & k for hsc2022
    tmp_factor = 0.01
    mean = counts_inter_mv['mean']
    var = counts_inter_mv['var']

    gamma_var = var - mean
    gamma_mean = mean
    if gamma_var <= 0:
        gamma_var = tmp_factor * gamma_mean

    if 'div4' in mods:
        gamma_var = gamma_var / np.square(4)
        gamma_mean = gamma_mean / 4

    gamma_theta = gamma_var / gamma_mean
    gamma_k = np.square(gamma_mean) / gamma_var

    counts_inter_mv['est_gamma_mean'] = gamma_mean
    counts_inter_mv['est_gamma_var'] = gamma_var
    counts_inter_mv['est_gamma_theta'] = gamma_theta
    counts_inter_mv['est_gamma_k'] = gamma_k

    # multiscale_rounds = 4
    # lengths_lowres = lengths
    # if multiscale_rounds > 1:
    #     fullres_struct_nan = find_beads_to_remove(
    #         counts_ambig, lengths=lengths, ploidy=1, multiscale_factor=1)
    # all_multiscale_factors = 2 ** np.arange(multiscale_rounds)
    # for multiscale_factor in all_multiscale_factors[1:]:
    #     counts_interchrom = decrease_counts_res(
    #         counts_interchrom, multiscale_factor=2, lengths=lengths_lowres,
    #         ploidy=ploidy)
    #     lengths_lowres = decrease_lengths_res(
    #         lengths_lowres, multiscale_factor=2)
    #     counts_interchrom = _inter_counts(
    #         counts_interchrom, lengths_at_res=lengths_lowres, ploidy=ploidy,
    #         exclude_zeros=False)
    #     fullres_per_lowres_bead = _count_fullres_per_lowres_bead(
    #         multiscale_factor=multiscale_factor, lengths=lengths,
    #         ploidy=1, fullres_struct_nan=fullres_struct_nan)
    #     mask = (fullres_per_lowres_bead == multiscale_factor)
    #     counts_interchrom[~mask, :] = np.nan
    #     counts_interchrom[:, ~mask] = np.nan
    #     tmp = counts_interchrom[~np.isnan(counts_interchrom)]
    #     if 'try1' in mods:
    #         tmp = tmp / 4

    #     nb_pmf_x = np.arange(tmp.max() + 1, dtype=int)
    #     nb_pmf_y = np.bincount(tmp.astype(int)) / tmp.size
    #     nb_pmf = {'x': nb_pmf_x, 'y': nb_pmf_y}
    #     counts_inter_mv[multiscale_factor] = {
    #         'mean': tmp.mean(), 'var': tmp.var(), 'nb_pmf': nb_pmf}

    if verbose:
        mean = counts_inter_mv['mean']
        var = counts_inter_mv['var']
        gamma_var = counts_inter_mv['est_gamma_var']
        theta = counts_inter_mv['est_gamma_theta']
        print(f"INTER-CHROM COUNTS, {1}X:\t  "
              f"mean={mean:.3g}\tvar={var:.3g}\tŒ∏={theta:.3g}"
              f"\tŒìvar={gamma_var:.3g}", flush=True)

    return counts_inter_mv


def taylor_approx_ndc(x, beta=1, alpha=-3, order=1):
    x = x / beta
    x_mean = np.mean(x)
    x_var = np.var(x)

    fx_mean = np.power(x_mean, 1 / alpha)
    fx_var = 1 / np.power(alpha, 2) * np.power(
        x_mean, (2 - 2 * alpha) / alpha) * x_var

    if order == 2:  # FIXME TODO
        tmp = (1 - alpha) / (2 * np.square(alpha)) * np.power(
            x_mean, (1 - 2 * alpha) / alpha)
        fx_mean = fx_mean + tmp * x_var
        fx_var = fx_var + np.square(tmp) * (np.var(
            np.square(x)) - 4 * np.square(x_mean) * x_var)

    fx_std = np.sqrt(fx_var)
    return fx_mean, fx_std


def _neighboring_bead_indices(lengths, ploidy, multiscale_factor=1,
                              counts=None, include_struct_nan_beads=True):
    """Return row & col of neighboring beads, along a homolog of a chromosome.
    """

    lengths_lowres = decrease_lengths_res(lengths, multiscale_factor)
    nbeads = lengths_lowres.sum() * ploidy

    row_nghbr = np.arange(nbeads - 1, dtype=int)

    # Optionally remove beads for which there is no counts data
    if not include_struct_nan_beads:
        if counts is None:
            raise ValueError(
                "Counts must be inputted if including struct_nan beads.")
        struct_nan = find_beads_to_remove(
            counts, lengths=lengths, ploidy=ploidy,
            multiscale_factor=multiscale_factor)
        nghbr_dis_mask = (~np.isin(row_nghbr, struct_nan)) & (
            ~np.isin(row_nghbr + 1, struct_nan))
        row_nghbr = row_nghbr[nghbr_dis_mask]

    # Remove if "neighbor" beads are actually on different chromosomes
    # or homologs
    bins = np.tile(lengths_lowres, ploidy).cumsum()
    same_bin = np.digitize(row_nghbr, bins) == np.digitize(row_nghbr + 1, bins)

    row_nghbr = row_nghbr[same_bin]

    return row_nghbr


def _inter_homolog_dis(struct, lengths):
    """Computes distance between homologs for a normal diploid structure.
    """

    struct = struct.copy().reshape(-1, 3)

    n = int(struct.shape[0] / 2)
    homo1 = struct[:n, :]
    homo2 = struct[n:, :]

    hmlg_dis = []
    begin = end = 0
    for i in range(lengths.size):
        end += lengths[i]
        if np.isnan(homo1[begin:end, 0]).sum() == lengths[i] or np.isnan(
                homo2[begin:end, 0]).sum() == lengths[i]:
            hmlg_dis.append(np.nan)
        else:
            hmlg_dis.append(((np.nanmean(homo1[
                begin:end, :], axis=0) - np.nanmean(
                homo2[begin:end, :], axis=0)) ** 2).sum() ** 0.5)
        begin = end

    hmlg_dis = np.array(hmlg_dis)
    hmlg_dis[np.isnan(hmlg_dis)] = np.nanmean(hmlg_dis)

    return hmlg_dis


def _inter_homolog_dis_via_simple_diploid(struct, lengths):
    """Computes distance between chromosomes for a faux-haploid structure.
    """

    from sklearn.metrics import euclidean_distances

    struct = struct.copy().reshape(-1, 3)

    chrom_barycenters = []
    begin = end = 0
    for i in range(lengths.size):
        end += lengths[i]
        if np.isnan(struct[begin:end, 0]).sum() < lengths[i]:
            chrom_barycenters.append(
                np.nanmean(struct[begin:end, :], axis=0).reshape(1, 3))
        begin = end

    chrom_barycenters = np.concatenate(chrom_barycenters)

    hmlg_dis = euclidean_distances(chrom_barycenters)
    hmlg_dis[np.tril_indices(hmlg_dis.shape[0])] = np.nan

    return np.full(lengths.shape, np.nanmean(hmlg_dis))


def distance_between_homologs(structures, lengths, mixture_coefs=None,
                              simple_diploid=False):
    """Computes distances between homologs for a given structure.

    For diploid organisms, this computes the distance between homolog centers
    of mass for each chromosome.

    Parameters
    ----------
    structures : array of float or list of array of float
        3D chromatin structure(s) for which to assess inter-homolog distances.
    lengths : array_like of int
        Number of beads per homolog of each chromosome.
    simple_diploid: bool, optional
        For diploid organisms: whether the structure is an inferred "simple
        diploid" structure in which homologs are assumed to be identical and
        completely overlapping with one another.

    Returns
    -------
    array of float
        Distance between homologs per chromosome.

    """

    from .utils_poisson import _format_structures

    structures = _format_structures(
        structures=structures, lengths=lengths,
        ploidy=(1 if simple_diploid else 2),
        mixture_coefs=mixture_coefs)

    hmlg_dis = []
    for struct in structures:
        if simple_diploid:
            hmlg_dis.append(_inter_homolog_dis_via_simple_diploid(
                struct=struct, lengths=lengths))
        else:
            hmlg_dis.append(_inter_homolog_dis(struct=struct, lengths=lengths))

    return np.mean(hmlg_dis, axis=0)
