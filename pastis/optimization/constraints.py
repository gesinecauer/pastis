import sys

if sys.version_info[0] < 3:
    raise Exception("Must be using Python 3")

import numpy as np
from scipy import sparse
import warnings

from .utils_poisson import _setup_jax
_setup_jax()
import jax.numpy as jnp
from jax.nn import relu
from jax.scipy.stats.nbinom import logpmf as logpmf_negbinom

from .multiscale_optimization import decrease_lengths_res, decrease_counts_res
from .multiscale_optimization import _count_fullres_per_lowres_bead
from .multiscale_optimization import decrease_bias_res
from .utils_poisson import find_beads_to_remove, _euclidean_distance
from .utils_poisson import _intermol_counts, _intramol_mask
from .utils_poisson import _dict_is_equal, _dict_to_hash
from .counts import ambiguate_counts, _ambiguate_beta, _get_nonzero_mask
from .counts import _get_included_counts_bins, _idx_isin, _get_bias_per_bin
from .likelihoods import poisson_nll, gamma_poisson_nll
from .poisson import get_gamma_moments
from ..io.read import load_data


class Constraint(object):
    """Compute loss for the given constraint.

    Prepares cand computes the loss function for the given constraint.

    Parameters
    ----------
    lambda_val : float
        Lambda that specifies how strongly constraint is applied during
        calculation of the entire objective.
    lengths : array_like of int
        Number of beads per homolog of each chromosome.
    ploidy : {1, 2}
        Ploidy, 1 indicates haploid, 2 indicates diploid.
    multiscale_factor : int, optional
        Factor by which to reduce the resolution. A value of 2 halves the
        resolution. A value of 1 indicates full resolution.
    multires_naive : bool, optional
        Whether to apply the naive multi-resolution model.
    hparams : dict, optional
        Any hyperparameters used for the calculation of constraint.
    fullres_struct_nan : array of int, optional
        Beads that should be removed (set to NaN) in the full-res structure.
    lowmem : bool, optional
        Whether variables generated by setup should be saved for subsequent
        iterations.

    Attributes
    ----------
    abbrev : str
        Three-letter abbreviation for constraint name.
    name : str
        Full name of constraint
    during_alpha_infer : bool
        Whether or not this constraint should be computed during inference of
        alpha.
    lambda_val : float
        Lambda that specifies how strongly constraint is applied during
        calculation of the entire objective.
    lengths : array of int
        Number of beads per homolog of each chromosome.
    lengths_lowres : array of int
        Number of beads per homolog of each chromosome, at the resolution being
        inferred.
    ploidy : {1, 2}
        Ploidy, 1 indicates haploid, 2 indicates diploid.
    multiscale_factor : int, optional
        Factor by which to reduce the resolution. A value of 2 halves the
        resolution. A value of 1 indicates full resolution.
    hparams : dict, optional
        Any hyperparameters used for the calculation of constraint.
    """

    def __init__(self, lambda_val, lengths, ploidy, multiscale_factor=1,
                 multires_naive=False, hparams=None, fullres_struct_nan=None,
                 lowmem=False, mods=()):
        self.abbrev = None
        self.name = None
        self.during_alpha_infer = None
        self.lambda_val = lambda_val
        self.lengths = np.array(lengths, copy=False, ndmin=1, dtype=int).ravel()
        self.lengths_lowres = decrease_lengths_res(
            self.lengths, multiscale_factor=multiscale_factor)
        self.ploidy = ploidy
        self.multiscale_factor = multiscale_factor
        self.multires_naive = multires_naive
        self.hparams = hparams
        self._fullres_struct_nan = fullres_struct_nan  # For self.setup() only
        self._lowmem = lowmem
        self._var = None

        self.check()

    @property
    def setup_completed(self):
        """TODO"""
        return self._lowmem or (self._var is not None)

    def __str__(self):
        return f"CONSTRAINT: {self.name:.<40s} LAMBDA={self.lambda_val:g}"

    def __eq__(self, other):
        if type(other) is type(self):
            if not _dict_is_equal(self.__dict__, other.__dict__):
                return False
            return True
        return NotImplemented

    def __hash__(self):
        return _dict_to_hash(self.__dict__)

    def check(self):
        """Check constraints object.

        Check that lambdas are greater than zero, and that necessary
        hyperparameters are supplied."""
        pass

    def setup(self, counts=None, bias=None):
        """Set up for applying constraint (not specific to inferred params)"""
        pass

    def apply(self, struct, alpha=None, beta=None, epsilon=None, counts=None, bias=None,
              inferring_alpha=False):

        """Apply constraint using given structure(s).

        Compute loss for the given constraint.

        Parameters
        ----------
        struct : ndarray
            3D chromatin structure(s) for which to compute the constraint.
        alpha : float
            Biophysical parameter of the transfer function used in converting
            counts to wish distances. If alpha is not specified, it will be
            inferred.
        epsilon : float, optional
            TODO
        counts : list of CountsMatrix subclass instances
            Preprocessed counts data.
        bias : array of float, optional
            Biases computed by ICE normalization.
        inferring_alpha : bool, optional
            A value of "True" indicates that the current optimization aims to
            infer alpha, rather than the structure.

        Returns
        -------
        constraint_obj
            Loss for constraint.
        """
        pass


class BeadChainConnectivity2019(Constraint):
    """TODO"""

    def __init__(self, lambda_val, lengths, ploidy, multiscale_factor=1,
                 multires_naive=False, hparams=None, fullres_struct_nan=None,
                 lowmem=False, mods=()):
        self.abbrev = "bcc"
        self.name = "Bead-chain connectivity (2019)"
        self.during_alpha_infer = False
        self.lambda_val = lambda_val
        self.lengths = np.array(lengths, copy=False, ndmin=1, dtype=int).ravel()
        self.lengths_lowres = decrease_lengths_res(
            self.lengths, multiscale_factor=multiscale_factor)
        self.ploidy = ploidy
        self.multiscale_factor = multiscale_factor
        self.multires_naive = multires_naive
        self.hparams = hparams
        self._fullres_struct_nan = None  # Not necessary for this constraint
        self._lowmem = lowmem
        self._var = None
        self.mods = mods

        self.check()

    def check(self):
        if self.lambda_val < 0:
            raise ValueError("Constraint lambda may not be < 0.")
        if self.hparams is not None and len(self.hparams) > 0:
            raise ValueError(f"{self.name} constraint may not have hyperparams")

    def setup(self, counts=None, bias=None):
        if self.lambda_val <= 0:
            return
        if self._var is not None:
            return self._var
        row_nghbr = _neighboring_bead_indices(
            lengths=self.lengths, ploidy=self.ploidy,
            multiscale_factor=self.multiscale_factor)

        var = {'row_nghbr': row_nghbr}
        if not self._lowmem:
            for k in var.keys():  # Make all arrays C-contiguous for hashing
                if isinstance(var[k], np.ndarray):
                    var[k] = np.asarray(var[k], order='C')
            self._var = var
        return var

    def apply(self, struct, alpha=None, beta=None, epsilon=None, counts=None, bias=None,
              inferring_alpha=False):
        if self.lambda_val == 0 or (
                inferring_alpha and not self.during_alpha_infer):
            return 0
        var = self.setup(counts=counts, bias=bias)

        nghbr_dis = _euclidean_distance(
            struct, row=var['row_nghbr'], col=var['row_nghbr'] + 1)
        n_edges = nghbr_dis.shape[0]
        nghbr_dis_var = n_edges * jnp.square(
            nghbr_dis).sum() / jnp.square(nghbr_dis.sum())
        obj = nghbr_dis_var - 1.

        if type(obj).__name__ in ('DeviceArray', 'ndarray') and not jnp.isfinite(obj):
            raise ValueError(f"{self.name} constraint is {obj}.")
        return self.lambda_val * obj


class HomologSeparating2019(Constraint):
    """TODO"""

    def __init__(self, lambda_val, lengths, ploidy, multiscale_factor=1,
                 multires_naive=False, hparams=None, fullres_struct_nan=None,
                 lowmem=False, mods=()):
        self.abbrev = "hsc"
        self.name = "Homolog separating (2019)"
        self.during_alpha_infer = False
        self.lambda_val = lambda_val
        self.lengths = np.array(lengths, copy=False, ndmin=1, dtype=int).ravel()
        self.lengths_lowres = decrease_lengths_res(
            self.lengths, multiscale_factor=multiscale_factor)
        self.ploidy = ploidy
        self.multiscale_factor = multiscale_factor
        self.multires_naive = multires_naive
        self.hparams = hparams
        self._fullres_struct_nan = None  # Not necessary for this constraint
        self._lowmem = lowmem
        self._var = None
        self.mods = mods

        self.check()

    def check(self):  # TODO flesh out check() for all constraints
        if self.ploidy == 1 and self.lambda_val > 0:
            raise ValueError(f"{self.name} constraint can not be applied to"
                             " haploid genomes.")
        if self.lambda_val < 0:
            raise ValueError("Constraint lambda may not be < 0.")

        # Hyperparam: perc_diff
        if self.hparams is None:
            self.hparams = {'perc_diff': None}
        if 'perc_diff' not in self.hparams:
            self.hparams['perc_diff'] = None
        if self.hparams['perc_diff'] is not None and (
                self.hparams['perc_diff'] < 0 or self.hparams['perc_diff'] > 1):
            raise ValueError("'perc_diff' must be between 0 and 1.")

        # Hyperparam: est_hmlg_sep
        if 'est_hmlg_sep' not in self.hparams or self.hparams[
                'est_hmlg_sep'] is None:
            raise ValueError(f"{self.name} constraint is missing neccessary"
                             " hyperparams: 'est_hmlg_sep'")
        if isinstance(self.hparams['est_hmlg_sep'], list):
            self.hparams['est_hmlg_sep'] = np.array(
                self.hparams['est_hmlg_sep']).ravel()
        if not isinstance(
                self.hparams['est_hmlg_sep'], (np.ndarray, float, int)):
            raise ValueError(f"{self.name} constraint hyperparam 'est_hmlg_sep'"
                             " not understood.")
        if isinstance(self.hparams['est_hmlg_sep'], np.ndarray):
            if self.hparams['est_hmlg_sep'].size not in (1, self.lengths.size):
                raise ValueError(f"{self.name} constraint hyperparam"
                                 " 'est_hmlg_sep' is not the correct size.")

        # Make all arrays C-contiguous for hashing
        for k in self.hparams.keys():
            if isinstance(self.hparams[k], np.ndarray):
                self.hparams[k] = np.asarray(self.hparams[k], order='C')


    def setup(self, counts=None, bias=None):
        if self.lambda_val <= 0:
            return
        if self._var is not None:
            return self._var

        bead_weights = _get_lowres_bead_weights(
            lengths=self.lengths, ploidy=self.ploidy,
            multiscale_factor=self.multiscale_factor,
            lengths_lowres=self.lengths_lowres)

        var = {'bead_weights': bead_weights}
        if not self._lowmem:
            for k in var.keys():  # Make all arrays C-contiguous for hashing
                if isinstance(var[k], np.ndarray):
                    var[k] = np.asarray(var[k], order='C')
            self._var = var
        return var

    def apply(self, struct, alpha=None, beta=None, epsilon=None, counts=None, bias=None,
              inferring_alpha=False):
        if self.lambda_val == 0 or (
                inferring_alpha and not self.during_alpha_infer):
            return 0
        var = self.setup(counts=counts, bias=bias)

        hmlg_sep = _get_homolog_separation(
            struct, lengths=self.lengths,
            multiscale_factor=self.multiscale_factor,
            lengths_lowres=self.lengths_lowres,
            bead_weights=var['bead_weights'])

        hmlg_sep_diff = self.hparams["est_hmlg_sep"] - hmlg_sep
        if 'rscale' in self.mods:
            hmlg_sep_diff = 1 - hmlg_sep / self.hparams["est_hmlg_sep"]
        if self.hparams['perc_diff'] is None:
            hmlg_sep_diff = relu(hmlg_sep_diff)
        else:
            hsc_cutoff = jnp.array(self.hparams['perc_diff'] * self.hparams[
                "est_hmlg_sep"])
            gt0 = hmlg_sep_diff > 0
            hmlg_sep_diff = hmlg_sep_diff.at[gt0].set(relu(
                hmlg_sep_diff[gt0] - hsc_cutoff[gt0]))
            hmlg_sep_diff = hmlg_sep_diff.at[~gt0].set(-relu(
                -(hmlg_sep_diff[~gt0] + hsc_cutoff[~gt0])))
        hmlg_sep_diff_sq = jnp.square(hmlg_sep_diff)
        obj = jnp.mean(hmlg_sep_diff_sq)

        if type(obj).__name__ in ('DeviceArray', 'ndarray') and not jnp.isfinite(obj):
            raise ValueError(f"{self.name} constraint is {obj}.")
        return self.lambda_val * obj


class BeadChainConnectivity2022(Constraint):
    """TODO"""

    def __init__(self, lambda_val, lengths, ploidy, multiscale_factor=1,
                 multires_naive=False, hparams=None, fullres_struct_nan=None,
                 lowmem=False, mods=()):
        self.abbrev = "bcc"
        self.name = "Bead-chain connectivity (2022)"
        self.during_alpha_infer = True and ('no_bcc_alpha' not in mods)
        self.lambda_val = lambda_val
        self.lengths = np.array(lengths, copy=False, ndmin=1, dtype=int).ravel()
        self.lengths_lowres = decrease_lengths_res(
            self.lengths, multiscale_factor=multiscale_factor)
        self.ploidy = ploidy
        self.multiscale_factor = multiscale_factor
        self.multires_naive = multires_naive
        self.hparams = hparams
        self._fullres_struct_nan = None  # Not necessary for this constraint
        self._lowmem = lowmem
        self._var = None
        self.mods = mods

        self.check()

    def check(self):
        if self.ploidy == 1 and self.lambda_val > 0:
            raise ValueError(f"{self.name} constraint can not be applied to"
                             " haploid genomes.")
        if self.lambda_val < 0:
            raise ValueError("Constraint lambda may not be < 0.")

        if 'bcc22_c_inter' in self.mods:
            if self.hparams is None or 'data_interchrom' not in self.hparams or (
                    self.hparams['data_interchrom'] is None):
                raise ValueError(f"{self.name} constraint is missing neccessary"
                                 f" hyperparam: 'data_interchrom'")

        # Hyperparam: fullres_per_lowres_bead
        if (self.multiscale_factor > 1 and self.multires_naive) and ((
                self.hparams is None) or (
                'fullres_per_lowres_bead' not in self.hparams) or (
                self.hparams['fullres_per_lowres_bead'] is None)):
            raise ValueError(f"{self.name} constraint is missing neccessary"
                             f" hyperparam: 'fullres_per_lowres_bead'")

        # Make all arrays C-contiguous for hashing
        for k in self.hparams.keys():
            if isinstance(self.hparams[k], np.ndarray):
                self.hparams[k] = np.asarray(self.hparams[k], order='C')

    def setup(self, counts=None, bias=None):
        if self.lambda_val <= 0:
            return
        if self._var is not None:
            return self._var

        # Get indices of neighboring beads
        row_nghbr = _neighboring_bead_indices(
            lengths=self.lengths, ploidy=self.ploidy,
            multiscale_factor=self.multiscale_factor)

        # Get counts corresponding to neighboring beads
        row_nghbr_ambig_lowres = _neighboring_bead_indices(
            lengths=self.lengths, ploidy=1,
            multiscale_factor=self.multiscale_factor)
        counts_nghbr_object = sum(counts).ambiguate().filter(
            row=row_nghbr_ambig_lowres, col=row_nghbr_ambig_lowres + 1,
            copy=False)

        mask_bin_nonzero = np.isin(
            row_nghbr_ambig_lowres, counts_nghbr_object.bins_nonzero.row)
        if counts_nghbr_object.bins_zero is None:
            mask_no_data = ~mask_bin_nonzero
        else:
            mask_bin_zero = np.isin(
                row_nghbr_ambig_lowres, counts_nghbr_object.bins_zero.row)
            mask_no_data = (~mask_bin_nonzero) & (~mask_bin_zero)
            assert np.array_equal(
                row_nghbr_ambig_lowres[mask_bin_zero],
                counts_nghbr_object.bins_zero.row)  # TODO remove
        assert np.array_equal(
            row_nghbr_ambig_lowres[mask_bin_nonzero],
            counts_nghbr_object.bins_nonzero.row)  # TODO remove

        if self.multiscale_factor == 1 or self.multires_naive:
            counts_nghbr_mask = None

            # Get counts associated with neighbor beads
            counts_nghbr = np.zeros(
                row_nghbr_ambig_lowres.size,
                dtype=counts_nghbr_object.bins_nonzero.data.dtype)
            counts_nghbr[
                mask_bin_nonzero] = counts_nghbr_object.bins_nonzero.data

            # If a distance bin has no counts associated with it,
            # set those counts to the mean of all counts
            if mask_no_data.sum() > 0:
                if counts_nghbr_object.bins_zero is None:
                    mean_counts_nghbr = np.mean(
                        counts_nghbr_object.bins_nonzero.data)
                else:
                    mean_counts_nghbr = np.mean(np.append(
                        counts_nghbr_object.bins_nonzero.data,
                        np.ones(counts_nghbr_object.bins_zero.nbins,
                            dtype=int)))
                if self.multiscale_factor > 1 and self.multires_naive:
                    fullres_per_lowres_dis = self.hparams[
                        'fullres_per_lowres_bead'][
                            row_nghbr_ambig_lowres] * self.hparams[
                        'fullres_per_lowres_bead'][row_nghbr_ambig_lowres + 1]
                    tmp = fullres_per_lowres_dis / np.square(
                        self.multiscale_factor)
                    mean_counts_nghbr = mean_counts_nghbr * tmp[mask_no_data]
                if np.issubdtype(counts_nghbr.dtype, np.integer):
                    mean_counts_nghbr = np.round(mean_counts_nghbr).astype(int)
                counts_nghbr[mask_no_data] = mean_counts_nghbr

        else:
            # Get mask associated with neighbor beads
            counts_nghbr_mask = _get_nonzero_mask(
                multiscale_factor=self.multiscale_factor, lengths=self.lengths,
                ploidy=self.ploidy, row=row_nghbr_ambig_lowres,
                col=row_nghbr_ambig_lowres + 1,
                empty_idx_fullres=counts_nghbr_object._empty_idx_fullres)
            if counts_nghbr_mask is None:
                counts_nghbr_mask = np.full(
                    (self.multiscale_factor ** 2, row_nghbr_ambig_lowres.size),
                    True)
            if mask_no_data.sum() > 0:
                counts_nghbr_mask[:, mask_no_data] = False
                counts_nghbr_mask[0, mask_no_data] = True
            if np.all(counts_nghbr_mask):
                counts_nghbr_mask = None

            # Get counts associated with neighbor beads
            counts_nghbr = np.zeros(
                (self.multiscale_factor ** 2, row_nghbr_ambig_lowres.size),
                dtype=counts_nghbr_object.bins_nonzero.data.dtype)
            counts_nghbr[
                :, mask_bin_nonzero] = counts_nghbr_object.bins_nonzero.data

            # If an entire lowres distance bin has no counts associated with it,
            # set those counts to the mean of all high-res counts
            if mask_no_data.sum() > 0:
                if counts_nghbr_object.bins_zero is None:
                    mean_counts_nghbr = np.mean(
                        counts_nghbr_object.bins_nonzero.data)
                else:
                    mean_counts_nghbr = np.mean(np.append(
                        counts_nghbr_object.bins_nonzero.data,
                        np.ones(counts_nghbr_object.bins_zero.nbins,
                            dtype=int)))
                if np.issubdtype(counts_nghbr.dtype, np.integer):
                    mean_counts_nghbr = int(np.round(mean_counts_nghbr))
                counts_nghbr[0, mask_no_data] = mean_counts_nghbr

            if counts_nghbr_mask is not None:
                counts_nghbr[~counts_nghbr_mask] = 0

        var = {
            'row_nghbr': row_nghbr, 'counts_nghbr': counts_nghbr,
            'counts_nghbr_mask': counts_nghbr_mask}
        if not self._lowmem:
            for k in var.keys():  # Make all arrays C-contiguous for hashing
                if isinstance(var[k], np.ndarray):
                    var[k] = np.asarray(var[k], order='C')
            self._var = var
        return var

    def apply(self, struct, alpha=None, beta=None, epsilon=None, counts=None, bias=None,
              inferring_alpha=False):
        if self.lambda_val == 0 or (
                inferring_alpha and not self.during_alpha_infer):
            return 0
        elif alpha is None:
            raise ValueError(f"Must input alpha for {self.name} constraint.")
        var = self.setup(counts=counts, bias=bias)

        # Beta for ambiguated counts
        beta_ambig = _ambiguate_beta(
            beta, counts=counts, lengths=self.lengths,
            ploidy=self.ploidy)

        bias_per_bin = _get_bias_per_bin(
            ploidy=self.ploidy, bias=bias, row=var['row_nghbr'],
            col=var['row_nghbr'] + 1, multiscale_factor=self.multiscale_factor,
            lengths=self.lengths, multires_naive=self.multires_naive)
        if var['counts_nghbr_mask'] is None:
            counts_nghbr_mask = None
        else:
            counts_nghbr_mask = np.tile(var['counts_nghbr_mask'], 2)

        if self.multiscale_factor == 1 or self.multires_naive:
            nghbr_dis = _euclidean_distance(
                struct, row=var['row_nghbr'], col=var['row_nghbr'] + 1)
            lambda_pois = (2 * beta_ambig) * jnp.power(nghbr_dis, alpha)
            if bias_per_bin is not None:
                lambda_pois = lambda_pois * bias_per_bin

            if 'bcc22_c_inter' in self.mods:
                counts_inter_mean = self.hparams['data_interchrom'][
                    self.multiscale_factor]['mean'] / 2
                lambda_pois = lambda_pois + counts_inter_mean
            if self.multiscale_factor > 1 and self.multires_naive:
                fullres_per_lowres_dis = self.hparams[
                    'fullres_per_lowres_bead'][var['row_nghbr']] * self.hparams[
                    'fullres_per_lowres_bead'][var['row_nghbr'] + 1]
            else:
                fullres_per_lowres_dis = 1

            obj = poisson_nll(
                np.tile(var['counts_nghbr'], 2), lambda_pois=lambda_pois,
                data_per_bin=fullres_per_lowres_dis)
        else:
            gamma_mean, gamma_var = get_gamma_moments(
                struct=struct, epsilon=epsilon, alpha=alpha,
                beta=beta_ambig, row3d=var['row_nghbr'],
                col3d=var['row_nghbr'] + 1, inferring_alpha=inferring_alpha, mods=self.mods)
            gamma_mean = gamma_mean * 2
            gamma_var = gamma_var * 4

            # Adjust using inter-chromosomal counts
            if 'bcc22_c_inter' in self.mods:
                counts_inter_mean = self.hparams['data_interchrom'][
                    self.multiscale_factor]['mean'] / 2
                gamma_mean = gamma_mean + counts_inter_mean

            theta = gamma_var / gamma_mean
            k = jnp.square(gamma_mean) / gamma_var
            obj = gamma_poisson_nll(
                theta=theta, k=k, data=np.tile(var['counts_nghbr'], 2),
                bias_per_bin=bias_per_bin, mask=counts_nghbr_mask, mods=self.mods)

        if 'debug2' in self.mods and type(obj).__name__ in ('DeviceArray', 'ndarray'):
            if not (self.multiscale_factor == 1 or self.multires_naive):
                lambda_pois = gamma_mean
            to_print = f"𝔼[c]={var['counts_nghbr'].mean():.2g}\t   μ={lambda_pois.mean():.2g}"
            if epsilon is not None:
                to_print += f"\t   V[c]={var['counts_nghbr'].var(axis=0).mean():.2g}"
                to_print += f"\t   σ²NB={(gamma_mean + gamma_var).mean():.2g}\t   ε={jnp.asarray(epsilon).mean():.2g}"
            to_print = to_print + f"\t   OBJ={obj:.2g}"
            import jax.debug as jax_debug
            jax_debug.print(to_print)

        if type(obj).__name__ in ('DeviceArray', 'ndarray') and not jnp.isfinite(obj):
            raise ValueError(f"{self.name} constraint is {obj}.")
        return self.lambda_val * obj


class HomologSeparating2022(Constraint):
    """TODO"""

    def __init__(self, lambda_val, lengths, ploidy, multiscale_factor=1,
                 multires_naive=False, hparams=None, fullres_struct_nan=None,
                 lowmem=False, mods=()):
        self.abbrev = "hsc"
        self.name = "Homolog separating (2022)"
        self.during_alpha_infer = True and ('no_hsc_alpha' not in mods)
        self.lambda_val = lambda_val
        self.lengths = np.array(lengths, copy=False, ndmin=1, dtype=int).ravel()
        self.lengths_lowres = decrease_lengths_res(
            self.lengths, multiscale_factor=multiscale_factor)
        self.ploidy = ploidy
        self.multiscale_factor = multiscale_factor
        self.multires_naive = multires_naive
        self.hparams = hparams
        self._fullres_struct_nan = None  # Not necessary for this constraint
        self._lowmem = lowmem
        self._var = None
        self.mods = mods

        self.check()

    def check(self):
        if self.ploidy == 1 and self.lambda_val > 0:
            raise ValueError(f"{self.name} constraint can not be applied to"
                             " haploid genomes.")
        if self.lambda_val < 0:
            raise ValueError("Constraint lambda may not be < 0.")

        # Hyperparam: data_interchrom
        if self.hparams is None or 'data_interchrom' not in self.hparams or (
                self.hparams['data_interchrom'] is None):
            raise ValueError(f"{self.name} constraint is missing neccessary"
                             f" hyperparam: 'data_interchrom'")

        # Hyperparam: fullres_per_lowres_bead
        if (self.multiscale_factor > 1 and self.multires_naive) and ((
                self.hparams is None) or (
                'fullres_per_lowres_bead' not in self.hparams) or (
                self.hparams['fullres_per_lowres_bead'] is None)):
            raise ValueError(f"{self.name} constraint is missing neccessary"
                             f" hyperparam: 'fullres_per_lowres_bead'")

        # Make all arrays C-contiguous for hashing
        for k in self.hparams.keys():
            if isinstance(self.hparams[k], np.ndarray):
                self.hparams[k] = np.asarray(self.hparams[k], order='C')

    def setup(self, counts=None, bias=None):
        if self.lambda_val <= 0:
            return
        if self._var is not None:
            return self._var

        bias_lowres = decrease_bias_res(
            bias, multiscale_factor=self.multiscale_factor, lengths=self.lengths)

        if self.lengths.size == 1:  # No inter-chrom if only 1 chrom
            mask_intrachrom = None
        else:
            n = self.lengths_lowres.sum()
            mask_intrachrom = _intramol_mask(
                (n, n), lengths_at_res=self.lengths_lowres)

        var = {'mask_intrachrom': mask_intrachrom, 'bias_lowres': bias_lowres}

        if not self._lowmem:
            for k in var.keys():  # Make all arrays C-contiguous for hashing
                if isinstance(var[k], np.ndarray):
                    var[k] = np.asarray(var[k], order='C')
            self._var = var
        return var

    def apply(self, struct, alpha=None, beta=None, epsilon=None, counts=None, bias=None,
              inferring_alpha=False):
        if self.lambda_val == 0 or (
                inferring_alpha and not self.during_alpha_infer):
            return 0
        elif alpha is None:
            raise ValueError(f"Must input alpha for {self.name} constraint.")
        var = self.setup(counts=counts, bias=bias)

        # Beta for ambiguated counts
        beta_ambig = _ambiguate_beta(
            beta, counts=counts, lengths=self.lengths,
            ploidy=self.ploidy)

        # Get inter-molecular indices
        n = self.lengths_lowres.sum()
        row, col = (x.ravel() for x in np.indices((n, n)))
        if not ('hsc22_combo' in self.mods or 'hsc22_quad' in self.mods):
            if self.lengths.size > 1:  # No inter-chrom if only 1 chrom
                row = row[var['mask_intrachrom']]
                col = col[var['mask_intrachrom']]
            idx = [[row, col + n]]
        else:
            raise ValueError("Not doing this anymore!")
            mask = col > row
            if self.lengths.size == 1:  # No inter-chrom if only 1 chrom
                row_interchrom = col_interchrom = None
            else:
                row_interchrom = row[mask & ~var['mask_intrachrom']]
                col_interchrom = col[mask & ~var['mask_intrachrom']]
            if 'hsc22_combo' in self.mods:
                if self.lengths.size == 1:  # No inter-chrom if only 1 chrom
                    row_all = row
                    col_all = col + n
                else:
                    row_all = np.concatenate(
                        [row, row_interchrom, row_interchrom + n])
                    col_all = np.concatenate(
                        [col + n, col_interchrom, col_interchrom + n])
                idx = [[row_all, col_all]]
            elif 'hsc22_quad' in self.mods:
                row = row[mask]
                col = col[mask]
                idx_h1h2 = [row, col + n]
                idx_h2h1 = [row + n, col]
                if self.lengths.size == 1:  # No inter-chrom if only 1 chrom
                    idx = [idx_h1h2, idx_h2h1]
                else:
                    idx_h1h1 = [row_interchrom, col_interchrom]
                    idx_h2h2 = [row_interchrom + n, col_interchrom + n]
                    idx = [idx_h1h2, idx_h2h1, idx_h1h1, idx_h2h2]

        # Get KL divergence
        obj = 0
        for row, col in idx:
            n, p = _get_hsc2022_negbinom(
                struct, row=row, col=col, alpha=alpha, beta=beta_ambig,
                multiscale_factor=self.multiscale_factor, epsilon=epsilon,
                bias_lowres=var["bias_lowres"],
                fullres_per_lowres_bead=self.hparams['fullres_per_lowres_bead'],
                inferring_alpha=inferring_alpha, mods=self.mods)
            log_lambda_pmf = logpmf_negbinom(
                self.hparams['data_interchrom'][self.multiscale_factor]['x'],
                n=n, p=p)
            obj = obj + _kl_divergence(
                p=self.hparams['data_interchrom'][self.multiscale_factor]['y'],
                log_q=log_lambda_pmf)

        if 'debug' in self.mods and type(obj).__name__ in ('DeviceArray', 'ndarray'):
            row_all = np.concatenate([row for row, col in idx])
            col_all = np.concatenate([col for row, col in idx])
            n, p = _get_hsc2022_negbinom(
                struct, row=row_all, col=col_all, alpha=alpha, beta=beta_ambig,
                multiscale_factor=self.multiscale_factor, epsilon=epsilon,
                bias_lowres=var["bias_lowres"],
                fullres_per_lowres_bead=self.hparams['fullres_per_lowres_bead'],
                inferring_alpha=inferring_alpha, mods=self.mods)
            nb_mean = (1 - p) * n / p
            nb_var = nb_mean / p

            alpha_beta = f"α={alpha:.3g}\tβ={beta_ambig:.3g}\t"

            to_print = f"{alpha_beta}KL_NB: 𝔼[c]={self.hparams['data_interchrom'][self.multiscale_factor]['mean']:.2g}\t   NBμ={nb_mean:.2g}\t   V[c]={self.hparams['data_interchrom'][self.multiscale_factor]['var']:.2g}\t   NBσ²={nb_var:.2g}"
            to_print += f"\t   OBJ={obj:.2g}"
            if epsilon is not None:
                to_print += f"\t   ε={jnp.asarray(epsilon).mean():.2g}"
                if jnp.asarray(epsilon).size > 1:
                    from .poisson import get_epsilon_per_bin
                    epsilon = get_epsilon_per_bin(
                        epsilon, row3d=row_all, col3d=col_all,
                        multiscale_factor=self.multiscale_factor)
                dis_interhmlg = _euclidean_distance(
                    struct, row=row_all, col=col_all)
                epsilon_over_dis = epsilon / dis_interhmlg
                to_print += f"\t   ε/D={epsilon_over_dis.mean():.2g}"
            import jax.debug as jax_debug
            print(to_print)

        if type(obj).__name__ in ('DeviceArray', 'ndarray') and not jnp.isfinite(obj):
            raise ValueError(f"{self.name} constraint is {obj}.")
        return self.lambda_val * obj


def _get_hsc2022_negbinom(struct, row, col, alpha, beta, multiscale_factor=1,
                          epsilon=None, bias_lowres=None,
                          fullres_per_lowres_bead=None,
                          inferring_alpha=False, mods=()):
    """TODO"""

    if multiscale_factor > 1 and epsilon is not None:
        lambda_mean, lambda_mixture_var = get_gamma_moments(
            struct=struct, epsilon=epsilon, alpha=alpha,
            beta=beta, row3d=row, col3d=col, inferring_alpha=inferring_alpha, mods=mods)
    else:
        lambda_mean = beta * jnp.power(
            _euclidean_distance(struct, row=row, col=col), alpha)
        lambda_mixture_var = None

        if multiscale_factor > 1:  # Naive multires approach
            fullres_per_lowres_dis = fullres_per_lowres_bead[
                row] * fullres_per_lowres_bead[col]
            lambda_mean = lambda_mean * fullres_per_lowres_dis

    # Multiply gamma distrib by bias
    if bias_lowres is not None and not np.all(bias_lowres == 1):
        bias_per_bin = _get_bias_per_bin(
            ploidy=2, bias=bias_lowres, row=row, col=col)
        lambda_mean = lambda_mean * bias_per_bin
        if lambda_mixture_var is not None:
            lambda_mixture_var = lambda_mixture_var * np.square(bias_per_bin)

    # Get gamma params: moment matching (full-res) or mixture model (low-res)
    mean = lambda_mean.mean()
    var = lambda_mean.var()
    if lambda_mixture_var is not None:
        var = var + jnp.mean(lambda_mixture_var)
    theta = var / mean
    k = jnp.square(mean) / var

    # Mulyiply gamma distrib by 4 to account for 4 combinations across hmlgs
    theta = theta * 4

    # Compound this gamma distrib with a Poisson to yield a negbinom distrib
    n = k
    p = 1 / (theta + 1)

    return n, p


def _kl_divergence(p, log_q, mean=True):
    """Measures KL divergence between two discrete distributions.

    Parameters
    ----------
    p : array
        The target probability distribution from the data.
    log_q : array
        The natural log of the approximated probability distribution.
    mean : bool, optional
        Divide by the number of entries in p.
    """
    mask = (p != 0)
    if mask.sum() == mask.size:
        tmp = p * (np.log(p) - log_q)
    else:
        tmp = p[mask] * (np.log(p[mask]) - log_q[mask])

    if mean:
        return jnp.mean(tmp)
    else:
        return jnp.sum(tmp)


def prep_constraints(lengths, ploidy, multiscale_factor=1, multiscale_reform=True,
                     bcc_lambda=0, hsc_lambda=0, bcc_version='2019',
                     hsc_version='2019', data_interchrom=None,
                     est_hmlg_sep=None, hsc_perc_diff=None,
                     fullres_struct_nan=None, verbose=True, mods=()):
    """TODO"""

    if mods is None:
        mods = []
    elif isinstance(mods, str):
        mods = mods.lower().split('.')
    else:
        mods = [x.lower() for x in mods]

    # Parse input
    if bcc_version is None:
        bcc_version = '2019'
    bcc_version = str(bcc_version)
    if hsc_version is None:
        hsc_version = '2019'
    hsc_version = str(hsc_version)

    if (not multiscale_reform) and multiscale_factor > 1:
        fullres_per_lowres_bead = _count_fullres_per_lowres_bead(
            multiscale_factor=multiscale_factor, lengths=lengths, ploidy=ploidy,
            fullres_struct_nan=fullres_struct_nan)

        # Adjust for low-res beads that would have otherwise been excluded
        mask0 = (fullres_per_lowres_bead == 0)  # lowres beads that nan
        fullres_per_lowres_bead[mask0] = _count_fullres_per_lowres_bead(
            multiscale_factor=multiscale_factor, lengths=lengths, ploidy=ploidy,
            fullres_struct_nan=None)[mask0]
    else:
        fullres_per_lowres_bead = None

    # Setup constraints
    bcc_class = {
        '2019': BeadChainConnectivity2019, '2022': BeadChainConnectivity2022}
    hsc_class = {
        '2019': HomologSeparating2019, '2022': HomologSeparating2022}
    bcc_hparams = {
        '2019': None,
        '2022': {'fullres_per_lowres_bead': fullres_per_lowres_bead,
                 'data_interchrom': data_interchrom}}
    hsc_hparams = {
        '2019': {'est_hmlg_sep': est_hmlg_sep, 'perc_diff': hsc_perc_diff},
        '2022': {'data_interchrom': data_interchrom,
                 'fullres_per_lowres_bead': fullres_per_lowres_bead}}
    constraints = []
    if bcc_lambda != 0:
        constraints.append(bcc_class[bcc_version](
            bcc_lambda, lengths=lengths, ploidy=ploidy,
            multiscale_factor=multiscale_factor, multires_naive=not multiscale_reform,
            hparams=bcc_hparams[bcc_version],
            fullres_struct_nan=fullres_struct_nan, lowmem=False, mods=mods))
    if hsc_lambda != 0:
        constraints.append(hsc_class[hsc_version](
            hsc_lambda, lengths=lengths, ploidy=ploidy,
            multiscale_factor=multiscale_factor, multires_naive=not multiscale_reform,
            hparams=hsc_hparams[hsc_version],
            fullres_struct_nan=fullres_struct_nan, lowmem=False, mods=mods))

    if verbose:
        for x in constraints:
            print(x, flush=True)

    return constraints  # List of Constraint objects


def _counts_interchrom(counts, lengths, ploidy, filter_threshold=0.04,
                       normalize=True, bias=None, multiscale_reform=True,
                       multiscale_factor=1, verbose=True, mods=()):
    """TODO"""

    counts, bias, lengths, _, _, _, _ = load_data(
        counts=counts, lengths_full=lengths, ploidy=ploidy,
        filter_threshold=filter_threshold, normalize=normalize, bias=bias,
        verbose=False)
    if lengths.size == 1:
        raise ValueError(
            "Must input counts_interchrom if inferring a single chromosome.")

    if not all([np.issubdtype(c.dtype, np.integer) for c in counts]):
        raise ValueError("Counts must be integer-valued to get PMF of"
                         " inter-chromosomal data.")

    # Reduce resolution (should only be done when using naive multires approach)
    counts_ambig = ambiguate_counts(
        counts=counts, lengths=lengths, ploidy=ploidy)
    if not multiscale_reform:
        counts_ambig = decrease_counts_res(
            counts_ambig, multiscale_factor=multiscale_factor, lengths=lengths,
            ploidy=ploidy)
        lengths = decrease_lengths_res(
            lengths, multiscale_factor=multiscale_factor)
    elif multiscale_factor > 1:
        warnings.warn("Inter-chrom counts will not be low-res unless"
                      f" multiscale_reform=False, ignoring {multiscale_factor=}")

    # Get inter-chromosomal ambiguated counts bins... for counts > 0
    counts_interchrom = _intermol_counts(
        counts_ambig, lengths_at_res=lengths, ploidy=ploidy)
    counts_interchrom = counts_interchrom.data

    # Get inter-chromosomal ambiguated counts bins... for counts == 0
    dummy = _get_included_counts_bins(
        counts_ambig, lengths=lengths, ploidy=ploidy,
        check_counts=False).astype(np.uint8)
    dummy -= counts_ambig.toarray().astype(bool).astype(np.uint8)  # Remove non0
    dummy = _intermol_counts(dummy, lengths_at_res=lengths, ploidy=ploidy)
    num_zero_bins_interchrom = dummy.nnz

    # Get inter-chromosomal ambiguated counts bins... for all counts
    counts_interchrom = np.append(
        counts_interchrom, np.zeros(num_zero_bins_interchrom, dtype=np.uint8))

    # Get distribution of ambiguated inter-chromosomal counts
    counts_pmf_x = np.arange(counts_interchrom.max() + 1, dtype=int)
    bincount_y = np.bincount(counts_interchrom.astype(int))
    counts_pmf_y = bincount_y / counts_interchrom.size
    mask = counts_pmf_y != 0
    counts_pmf_x = counts_pmf_x[mask]
    counts_pmf_y = counts_pmf_y[mask]

    if verbose:
        tmp = f" ({multiscale_factor}x)" if not multiscale_reform else ""
        print(f"INTER-CHROM COUNTS{tmp}: mean={counts_interchrom.mean():.3g}\t"
              f"var={counts_interchrom.var():.3g}", flush=True)
    return {
        'x': counts_pmf_x, 'y': counts_pmf_y,
        'mean': counts_interchrom.mean(), 'var': counts_interchrom.var()}


def get_counts_interchrom(counts, lengths, ploidy, filter_threshold=0.04,
                          normalize=True, bias=None, multiscale_reform=True,
                          multiscale_rounds=1, verbose=True, mods=()):
    """TODO"""

    all_multiscale_factors = 2 ** np.flip(np.arange(int(multiscale_rounds)))

    if multiscale_reform:
        fullres_interchrom = _counts_interchrom(
            counts, lengths=lengths, ploidy=ploidy,
            filter_threshold=filter_threshold, normalize=normalize,
            bias=bias, multiscale_reform=multiscale_reform,
            multiscale_factor=1, verbose=verbose, mods=mods)
        data_interchrom = {
            x: fullres_interchrom for x in all_multiscale_factors}
    else:
        data_interchrom = {}
        for multiscale_factor in all_multiscale_factors:
            data_interchrom[multiscale_factor] = _counts_interchrom(
                counts, lengths=lengths, ploidy=ploidy,
                filter_threshold=filter_threshold, normalize=normalize,
                bias=bias, multiscale_reform=multiscale_reform,
                multiscale_factor=multiscale_factor, verbose=verbose, mods=mods)

    return data_interchrom


def _neighboring_bead_indices(lengths, ploidy, multiscale_factor=1,
                              counts=None, include_struct_nan_beads=True):
    """Return row & col of neighboring beads on the same molecule."""

    lengths_lowres = decrease_lengths_res(lengths, multiscale_factor)
    nbeads = lengths_lowres.sum() * ploidy

    row_nghbr = np.arange(nbeads - 1, dtype=int)

    # Optionally remove beads for which there is no counts data
    if not include_struct_nan_beads:
        if counts is None:
            raise ValueError("If excluding struct_nan beads, must input counts")
        struct_nan = find_beads_to_remove(
            counts, lengths=lengths, ploidy=ploidy,
            multiscale_factor=multiscale_factor)
        nghbr_dis_mask = (~np.isin(row_nghbr, struct_nan)) & (
            ~np.isin(row_nghbr + 1, struct_nan))
        row_nghbr = row_nghbr[nghbr_dis_mask]

    # Remove if "neighbor" beads are actually on different chromosomes
    # or homologs
    bins = np.tile(lengths_lowres, ploidy).cumsum()
    same_bin = np.digitize(row_nghbr, bins) == np.digitize(row_nghbr + 1, bins)

    row_nghbr = row_nghbr[same_bin]

    row_nghbr = np.asarray(
        row_nghbr, dtype=np.min_scalar_type(row_nghbr.max()), order='C')

    return row_nghbr


def _get_lowres_bead_weights(lengths, ploidy, multiscale_factor=1,
                             lengths_lowres=None):
    """TODO"""

    if lengths_lowres is None:
        lengths_lowres = decrease_lengths_res(
            lengths, multiscale_factor=multiscale_factor)

    if multiscale_factor > 1:
        fullres_per_lowres_bead = _count_fullres_per_lowres_bead(
            multiscale_factor=multiscale_factor, lengths=lengths,
            ploidy=ploidy)
        bead_weights = fullres_per_lowres_bead / multiscale_factor
    else:
        bead_weights = np.ones((lengths_lowres.sum() * ploidy,))

    n = lengths_lowres.sum()
    begin = end = 0
    for i in range(lengths_lowres.size):
        end = end + lengths_lowres[i]
        bead_weights[begin:end] /= np.sum(bead_weights[begin:end])
        bead_weights[(n + begin):(n + end)] /= np.sum(
            bead_weights[(n + begin):(n + end)])
        begin = end
    bead_weights = bead_weights.reshape(-1, 1)

    return bead_weights


def _get_homolog_separation(struct, lengths, multiscale_factor=1,
                            lengths_lowres=None, bead_weights=None):
    """TODO"""

    if lengths_lowres is None:
        lengths_lowres = decrease_lengths_res(
            lengths, multiscale_factor=multiscale_factor)

    if bead_weights is None:
        bead_weights = _get_lowres_bead_weights(
            lengths=lengths, ploidy=2, multiscale_factor=multiscale_factor,
            lengths_lowres=lengths_lowres)

    struct_weighted = struct * bead_weights
    n = lengths_lowres.sum()
    hmlg_sep = jnp.zeros(lengths_lowres.size)
    begin = end = 0
    for i in range(lengths_lowres.size):
        end = end + lengths_lowres[i]
        hmlg1_mean = jnp.sum(struct_weighted[begin:end], axis=0)
        hmlg2_mean = jnp.sum(struct_weighted[(n + begin):(n + end)], axis=0)
        hmlg_sep_i = jnp.sqrt(jnp.sum(jnp.square(hmlg1_mean - hmlg2_mean)))
        hmlg_sep = hmlg_sep.at[i].set(hmlg_sep_i)
        begin = end

    return hmlg_sep
